{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:29:40.754425Z",
     "iopub.status.busy": "2021-08-03T05:29:40.753170Z",
     "iopub.status.idle": "2021-08-03T05:29:49.705958Z",
     "shell.execute_reply": "2021-08-03T05:29:49.705019Z",
     "shell.execute_reply.started": "2021-06-15T04:13:13.062336Z"
    },
    "papermill": {
     "duration": 8.973347,
     "end_time": "2021-08-03T05:29:49.706129",
     "exception": false,
     "start_time": "2021-08-03T05:29:40.732782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:29:49.746097Z",
     "iopub.status.busy": "2021-08-03T05:29:49.745096Z",
     "iopub.status.idle": "2021-08-03T05:29:56.425922Z",
     "shell.execute_reply": "2021-08-03T05:29:56.425003Z",
     "shell.execute_reply.started": "2021-06-15T04:20:06.962054Z"
    },
    "papermill": {
     "duration": 6.702917,
     "end_time": "2021-08-03T05:29:56.426066",
     "exception": false,
     "start_time": "2021-08-03T05:29:49.723149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import efficientnet.tfkeras as efn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:29:56.463846Z",
     "iopub.status.busy": "2021-08-03T05:29:56.463178Z",
     "iopub.status.idle": "2021-08-03T05:29:56.643513Z",
     "shell.execute_reply": "2021-08-03T05:29:56.644040Z",
     "shell.execute_reply.started": "2021-06-15T04:13:30.066138Z"
    },
    "papermill": {
     "duration": 0.201296,
     "end_time": "2021-08-03T05:29:56.644217",
     "exception": false,
     "start_time": "2021-08-03T05:29:56.442921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:29:56.680275Z",
     "iopub.status.busy": "2021-08-03T05:29:56.679651Z",
     "iopub.status.idle": "2021-08-03T05:29:56.685114Z",
     "shell.execute_reply": "2021-08-03T05:29:56.685658Z",
     "shell.execute_reply.started": "2021-06-15T04:13:30.452975Z"
    },
    "papermill": {
     "duration": 0.024922,
     "end_time": "2021-08-03T05:29:56.685855",
     "exception": false,
     "start_time": "2021-08-03T05:29:56.660933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_float(minval=0.0, maxval=1.0):\n",
    "    rnd = tf.random.uniform(\n",
    "        [], minval=minval, maxval=maxval, dtype=tf.float32)\n",
    "    return rnd\n",
    "\n",
    "def choice(p, image1, mask1, image2, mask2):\n",
    "    rnd = random_float()\n",
    "    image = tf.where(rnd <= p, image1, image2)\n",
    "    mask = tf.where(rnd <= p, mask1, mask2)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:29:56.721999Z",
     "iopub.status.busy": "2021-08-03T05:29:56.721413Z",
     "iopub.status.idle": "2021-08-03T05:29:56.724732Z",
     "shell.execute_reply": "2021-08-03T05:29:56.725233Z",
     "shell.execute_reply.started": "2021-06-15T04:20:33.930506Z"
    },
    "papermill": {
     "duration": 0.022916,
     "end_time": "2021-08-03T05:29:56.725380",
     "exception": false,
     "start_time": "2021-08-03T05:29:56.702464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_size = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:29:56.763661Z",
     "iopub.status.busy": "2021-08-03T05:29:56.762755Z",
     "iopub.status.idle": "2021-08-03T05:29:56.822212Z",
     "shell.execute_reply": "2021-08-03T05:29:56.822778Z",
     "shell.execute_reply.started": "2021-06-15T04:13:30.4625Z"
    },
    "papermill": {
     "duration": 0.080675,
     "end_time": "2021-08-03T05:29:56.822957",
     "exception": false,
     "start_time": "2021-08-03T05:29:56.742282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def HorizontalFlip(p):\n",
    "    def _do_horizontal_flip(image, mask):\n",
    "        aug_image = tf.image.flip_left_right(image)\n",
    "        aug_mask = tf.image.flip_left_right(mask)\n",
    "        return choice(p, aug_image, aug_mask, image, mask)\n",
    "    return _do_horizontal_flip\n",
    "def RandomBrightness(max_delta, p):\n",
    "    def _do_random_brightness(image, mask):\n",
    "        aug_image = tf.image.random_brightness(image, max_delta)\n",
    "        return choice(p, aug_image, mask, image, mask)\n",
    "    return _do_random_brightness\n",
    "def RandomContrast(lower, upper, p):\n",
    "    def _do_random_contrast(image, mask):\n",
    "        aug_image = tf.image.random_contrast(image, lower, upper)\n",
    "        return choice(p, aug_image, mask, image, mask)\n",
    "    return _do_random_contrast\n",
    "def initUndistortRectifyMap(height, width, k, dx, dy):\n",
    "    height = tf.cast(height, dtype=tf.float32)\n",
    "    width = tf.cast(width, dtype=tf.float32)\n",
    "    \n",
    "    f_x = width\n",
    "    f_y = height\n",
    "    c_x = width * 0.5 + dx\n",
    "    c_y = height * 0.5 + dy\n",
    "    \n",
    "    f_dash_x = f_x\n",
    "    c_dash_x = (width - 1.0) * 0.5\n",
    "    f_dash_y = f_y\n",
    "    c_dash_y = (height - 1.0) * 0.5\n",
    "\n",
    "    h_rng = tf.range(height, dtype=tf.float32)\n",
    "    w_rng = tf.range(width, dtype=tf.float32)\n",
    "    v, u = tf.meshgrid(h_rng, w_rng)\n",
    "    \n",
    "    x = (u - c_dash_x) / f_dash_x\n",
    "    y = (v - c_dash_y) / f_dash_y\n",
    "    x_dash = x\n",
    "    y_dash = y\n",
    "    \n",
    "    r_2 = x_dash * x_dash + y_dash * y_dash\n",
    "    r_4 = r_2 * r_2\n",
    "    x_dash_dash = x_dash * (1 + k*r_2 + k*r_4)\n",
    "    y_dash_dash = y_dash * (1 + k*r_2 + k*r_4)\n",
    "\n",
    "    map_x = x_dash_dash * f_x + c_x\n",
    "    map_y = y_dash_dash * f_y + c_y\n",
    "    return map_x, map_y\n",
    "\n",
    "def OpticalDistortion(distort_limit, shift_limit, p=1.0):\n",
    "    def _do_optical_distortion(image, mask):\n",
    "        k = random_float(-distort_limit, distort_limit)\n",
    "        dx = random_float(-shift_limit, shift_limit)\n",
    "        dy = random_float(-shift_limit, shift_limit)\n",
    "        image_shape = tf.shape(image)\n",
    "        height = image_shape[0]\n",
    "        width = image_shape[1]\n",
    "        map_x, map_y = initUndistortRectifyMap(\n",
    "            height, width, k, dx, dy)\n",
    "        aug_image = remap(\n",
    "            image, height, width, map_x, map_y, mode='mirror')\n",
    "        aug_mask = remap(\n",
    "            mask, height, width, map_x, map_y, mode='mirror')\n",
    "        return choice(p, aug_image, aug_mask, image, mask)\n",
    "    return _do_optical_distortion\n",
    "\n",
    "def make_grid_distorted_maps(height, width, num_steps, xsteps, ysteps):\n",
    "    def _make_maps_before_last(size, step, steps): # size=512, step=102,\n",
    "                                                   # steps.shape=[num_steps]\n",
    "        step_rep = tf.repeat(step, num_steps)  # [102, 102, 102, 102, 102]\n",
    "        step_rep_f = tf.cast(step_rep, dtype=tf.float32)\n",
    "        step_inc = step_rep_f * steps          # [102*s_0, ..., 102*s_4]\n",
    "        cur = tf.math.cumsum(step_inc)         # [si_0, si_0 + si_1, ... ]\n",
    "        zero = tf.zeros([1], dtype=tf.float32)\n",
    "        prev = tf.concat([ zero, cur[ :-1] ], axis=0) # [0, c_0, ..., c_3]\n",
    "        prev_cur = tf.stack([prev, cur])       # [[p_0, p_1, ...], [c_0, c_1, ...]]\n",
    "        ranges = tf.transpose(prev_cur)        # [[p_0, c_0], [p_1, c_1], ... ]\n",
    "\n",
    "        def _linspace_range(rng):\n",
    "            return tf.linspace(rng[0], rng[1], step)\n",
    " \n",
    "        maps_stack = tf.map_fn(_linspace_range, ranges)\n",
    "        maps = tf.reshape(maps_stack, [-1])    # [-1] flatten into 1-D\n",
    "        return maps\n",
    "    \n",
    "    def _make_last_map(size, step, last_start):\n",
    "        last_step = size - step * num_steps  # 512 - 102*5 = 2 \n",
    "        size_f = tf.cast(size, dtype=tf.float32)\n",
    "        last_map = tf.linspace(last_start, size_f-1.0, last_step)\n",
    "        return last_map\n",
    "    \n",
    "    def _make_distorted_map(size, steps):\n",
    "        step = size // num_steps               # step=102 \n",
    "        maps_before_last = _make_maps_before_last(size, step, steps[ :-1 ])\n",
    "        last_map = _make_last_map(size, step, maps_before_last[-1])\n",
    "        distorted_map = tf.concat([maps_before_last, last_map], axis=0)\n",
    "        return distorted_map\n",
    "\n",
    "    xx = _make_distorted_map(width, xsteps)\n",
    "    yy = _make_distorted_map(height, ysteps)\n",
    "    map_y, map_x = tf.meshgrid(xx, yy)\n",
    "    return map_x, map_y\n",
    "\n",
    "def GridDistortion(num_steps, distort_limit, p=1.0):\n",
    "    def _do_grid_distortion(image, mask):\n",
    "        xsteps = tf.random.uniform(\n",
    "            [num_steps + 1],\n",
    "            minval=1.0 - distort_limit,\n",
    "            maxval=1.0 + distort_limit)\n",
    "        ysteps = tf.random.uniform(\n",
    "            [num_steps + 1],\n",
    "            minval=1.0 - distort_limit,\n",
    "            maxval=1.0 + distort_limit)\n",
    "\n",
    "        image_shape = tf.shape(image)\n",
    "        height = image_shape[0]\n",
    "        width = image_shape[1]\n",
    "        map_x, map_y = make_grid_distorted_maps(\n",
    "            height, width, num_steps, xsteps, ysteps)\n",
    "        aug_image = remap(\n",
    "            image, height, width, map_x, map_y, mode='mirror')\n",
    "        aug_mask = remap(\n",
    "            mask, height, width, map_x, map_y, mode='mirror')\n",
    "        return choice(p, aug_image, aug_mask, image, mask)\n",
    "    return _do_grid_distortion\n",
    "def OneOf(trans1, trans2, p):\n",
    "    def _do_one_of(image, mask):\n",
    "        image1, mask1 = trans1(image, mask)\n",
    "        image2, mask2 = trans2(image, mask)\n",
    "        aug_image, aug_mask = choice(\n",
    "            0.5, image1, mask1, image2, mask2)\n",
    "        return choice(p, aug_image, aug_mask, image, mask)\n",
    "    return _do_one_of\n",
    "def HueSaturationValue(\n",
    "        hue_shift_limit, sat_shift_limit, val_shift_limit, p):\n",
    "    def _do_hue_saturation_value(image, mask):\n",
    "        hsv_image = tf.image.rgb_to_hsv(image)\n",
    "        hue_shift = random_float(-hue_shift_limit, hue_shift_limit)\n",
    "        sat_shift = random_float(-sat_shift_limit, sat_shift_limit)\n",
    "        val_shift = random_float(-val_shift_limit, val_shift_limit)\n",
    "\n",
    "        hue_values = (hsv_image[ ... , :1 ] + hue_shift) % 1.0\n",
    "        sat_values = tf.clip_by_value(\n",
    "            hsv_image[ ... , 1:2 ] + sat_shift, 0.0, 1.0)\n",
    "        val_values = tf.clip_by_value(\n",
    "            hsv_image[ ... , 2: ] + val_shift, 0.0, 1.0)\n",
    "        hsv_image = tf.concat(\n",
    "            [hue_values, sat_values, val_values], axis=-1)\n",
    "        aug_image = tf.image.hsv_to_rgb(hsv_image)\n",
    "        return choice(p, aug_image, mask, image, mask)\n",
    "    return _do_hue_saturation_value\n",
    "def affine_transform(height, width, tx, ty, z, theta):\n",
    "    cx = (width - 1.0) * 0.5\n",
    "    cy = (height - 1.0) * 0.5\n",
    "    \n",
    "    center_shift_mat = tf.convert_to_tensor([\n",
    "        [1.0, 0.0, -cx],\n",
    "        [0.0, 1.0, -cy],\n",
    "        [0.0, 0.0, 1.0]], dtype=tf.float32)\n",
    "    trans_mat = center_shift_mat\n",
    "    \n",
    "    rot_rad = -2.0 * math.pi * theta / 360.0\n",
    "    roration_mat = tf.convert_to_tensor([\n",
    "        [tf.math.cos(rot_rad), tf.math.sin(rot_rad), 0.0],\n",
    "        [-tf.math.sin(rot_rad), tf.math.cos(rot_rad), 0.0],\n",
    "        [0.0, 0.0, 1.0]], dtype=tf.float32)\n",
    "    trans_mat = tf.linalg.matmul(roration_mat, trans_mat)\n",
    "    \n",
    "    shift_mat = tf.convert_to_tensor([\n",
    "        [1.0, 0.0, cx - tx],\n",
    "        [0.0, 1.0, cy - ty],\n",
    "        [0.0, 0.0, 1.0]], dtype=tf.float32)\n",
    "    trans_mat = tf.linalg.matmul(shift_mat, trans_mat)\n",
    "\n",
    "    zoom_mat = tf.convert_to_tensor([\n",
    "        [1.0 / z, 0.0, 0.0],\n",
    "        [0.0, 1.0 / z, 0.0],\n",
    "        [0.0, 0.0, 1.0]], dtype=tf.float32)\n",
    "    trans_mat = tf.linalg.matmul(zoom_mat, trans_mat)\n",
    "    \n",
    "    h_rng = tf.range(height, dtype=tf.float32)\n",
    "    w_rng = tf.range(width, dtype=tf.float32)\n",
    "    y, x = tf.meshgrid(h_rng, w_rng)\n",
    "    x = tf.reshape(x, [-1])\n",
    "    y = tf.reshape(y, [-1])\n",
    "    ones = tf.ones_like(x)\n",
    "    coord_mat = tf.stack([x, y, ones])\n",
    "    \n",
    "    res_mat = tf.linalg.matmul(trans_mat, coord_mat)\n",
    "    map_x = res_mat[0]\n",
    "    map_y = res_mat[1]\n",
    "    return map_x, map_y\n",
    "\n",
    "def ShiftScaleRotate(\n",
    "        shift_limit, scale_limit, rotate_limit, p):\n",
    "    def _do_shift_scale_rotate(image, mask):\n",
    "        image_shape = tf.shape(image)\n",
    "        height_i = image_shape[0]\n",
    "        width_i = image_shape[1]\n",
    "        height_f = tf.cast(height_i, dtype=tf.float32)\n",
    "        width_f = tf.cast(width_i, dtype=tf.float32)\n",
    "        tx = width_f * random_float(-shift_limit, shift_limit)\n",
    "        ty = height_f * random_float(-shift_limit, shift_limit)\n",
    "        z = random_float(1.0 - scale_limit, 1.0 + scale_limit)\n",
    "        theta = random_float(-rotate_limit, rotate_limit)\n",
    "\n",
    "        map_x, map_y = affine_transform(\n",
    "            height_f, width_f, tx, ty, z, theta)\n",
    "        aug_image = remap(\n",
    "            image, height_i, width_i, map_x, map_y, mode='constant')\n",
    "        aug_mask = remap(\n",
    "            mask, height_i, width_i, map_x, map_y, mode='constant')\n",
    "        return choice(p, aug_image, aug_mask, image, mask)\n",
    "    return _do_shift_scale_rotate\n",
    "\n",
    "def randints(shape, minval, maxval):\n",
    "    # maxval+1 to include maxval for the result.\n",
    "    # generated range is [minval, maxval) (maxval is not included)\n",
    "    return tf.random.uniform(\n",
    "        shape=shape, minval=minval, maxval=maxval+1, dtype=tf.int32)\n",
    "\n",
    "def make_range_masks(size, starts, ends):\n",
    "    indice = tf.range(size, dtype=tf.int32)\n",
    "    start_masks = (\n",
    "        starts[ : , tf.newaxis] <= indice[  tf.newaxis, : ])\n",
    "    end_masks = (\n",
    "        indice[ tf.newaxis, : ] <= ends[ : , tf.newaxis])\n",
    "    range_masks = start_masks & end_masks\n",
    "    return range_masks\n",
    "\n",
    "def make_region_mask(tops, lefts, bottoms, rights):\n",
    "    row_masks = make_range_masks(image_size, tops, bottoms)\n",
    "    col_masks = make_range_masks(image_size, lefts, rights)\n",
    "    region_masks = \\\n",
    "        row_masks[ : , : , tf.newaxis ] & \\\n",
    "        col_masks[ : , tf.newaxis, : ]\n",
    "    region_mask = tf.math.reduce_any(region_masks, axis=0)\n",
    "    region_mask = region_mask[ : , : , tf.newaxis]\n",
    "    return region_mask\n",
    "\n",
    "def Cutout(num_cuts, mask_factor, p):\n",
    "    def _do_cutout(image, mask):\n",
    "        image_shape = tf.shape(image)\n",
    "        height_i = image_shape[0]\n",
    "        width_i = image_shape[1]\n",
    "        height_f = tf.cast(height_i, dtype=tf.float32)\n",
    "        width_f = tf.cast(width_i, dtype=tf.float32)\n",
    "        cut_h = tf.cast(height_f * mask_factor, dtype=tf.int32)\n",
    "        cut_w = tf.cast(width_f * mask_factor, dtype=tf.int32)\n",
    "\n",
    "        y_centers = randints([num_cuts], 0, image_size - 1)\n",
    "        x_centers = randints([num_cuts], 0, image_size - 1)\n",
    "        tops = tf.math.maximum(y_centers - cut_h//2, 0)\n",
    "        lefts = tf.math.maximum(x_centers - cut_w//2, 0)\n",
    "        bottoms = tf.math.minimum(tops + cut_h, height_i - 1)\n",
    "        rights = tf.math.minimum(lefts + cut_w, width_i - 1)\n",
    "\n",
    "        cut_region = make_region_mask(tops, lefts, bottoms, rights)\n",
    "        mask_value = tf.constant(0.0, dtype=tf.float32)\n",
    "        aug_image = tf.where(cut_region, mask_value, image)\n",
    "        return choice(p, aug_image, mask, image, mask)\n",
    "    return _do_cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:29:56.860087Z",
     "iopub.status.busy": "2021-08-03T05:29:56.859365Z",
     "iopub.status.idle": "2021-08-03T05:29:56.878250Z",
     "shell.execute_reply": "2021-08-03T05:29:56.877716Z",
     "shell.execute_reply.started": "2021-06-15T04:19:08.639778Z"
    },
    "papermill": {
     "duration": 0.038753,
     "end_time": "2021-08-03T05:29:56.878394",
     "exception": false,
     "start_time": "2021-08-03T05:29:56.839641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " def mirror_boundary(v, max_v):\n",
    "    # v % (max_v*2.0-2.0) ==> v % (512*2-2) ==> [0..1022]\n",
    "    # [0..1022] - (max_v-1.0) ==> [0..1022] - 511 ==> [-511..511]\n",
    "    # -1.0 * abs([-511..511]) ==> [-511..0]\n",
    "    # [-511..0] + max_v - 1.0 ==> [-511..0] + 511 ==> [0..511]\n",
    "    mirror_v = -1.0 * tf.math.abs(\n",
    "        v % (max_v*2.0-2.0) - (max_v-1.0)) + max_v-1.0\n",
    "    return mirror_v\n",
    "\n",
    "def clip_boundary(v, max_v):\n",
    "    clip_v = tf.clip_by_value(v, 0.0, max_v-1.0)\n",
    "    return clip_v\n",
    "\n",
    "def interpolate_bilinear(image, map_x, map_y):\n",
    "    def _gather(image, map_x, map_y):\n",
    "        map_stack = tf.stack([map_x, map_y]) # [ 2, height, width ]\n",
    "        map_indices = tf.transpose(\n",
    "            map_stack, perm=[1, 2, 0])       # [ height, width, 2 ]\n",
    "        map_indices = tf.cast(map_indices, dtype=tf.int32)\n",
    "        gather_image = tf.gather_nd(image, map_indices)\n",
    "        return gather_image\n",
    "    \n",
    "    ll = _gather(image, tf.math.floor(map_x), tf.math.floor(map_y))\n",
    "    lr = _gather(image, tf.math.ceil(map_x), tf.math.floor(map_y))\n",
    "    ul = _gather(image, tf.math.floor(map_x), tf.math.ceil(map_y))\n",
    "    ur = _gather(image, tf.math.ceil(map_x), tf.math.ceil(map_y))\n",
    "    \n",
    "    fraction_x = tf.expand_dims(map_x % 1.0, axis=-1) # [h, w, 1]\n",
    "    int_l = (lr - ll) * fraction_x + ll\n",
    "    int_u = (ur - ul) * fraction_x + ul\n",
    "    \n",
    "    fraction_y = tf.expand_dims(map_y % 1.0, axis=-1) # [h, w, 1]\n",
    "    interpolate_image = (int_u - int_l) * fraction_y + int_l\n",
    "    return interpolate_image\n",
    "\n",
    "def remap(image, height, width, map_x, map_y, mode):\n",
    "    assert \\\n",
    "        mode in ('mirror', 'constant'), \\\n",
    "        \"mode is neither 'mirror' nor 'constant'\"\n",
    "\n",
    "    height_f = tf.cast(height, dtype=tf.float32)\n",
    "    width_f = tf.cast(width, dtype=tf.float32)\n",
    "    map_x = tf.reshape(map_x, shape=[height, width])\n",
    "    map_y = tf.reshape(map_y, shape=[height, width])\n",
    "    if mode == 'mirror':\n",
    "        b_map_x = mirror_boundary(map_x, width_f)\n",
    "        b_map_y = mirror_boundary(map_y, height_f)\n",
    "    else:\n",
    "        b_map_x = clip_boundary(map_x, width_f)\n",
    "        b_map_y = clip_boundary(map_y, height_f)\n",
    "        \n",
    "    image_remap = interpolate_bilinear(image, b_map_x, b_map_y)\n",
    "    \n",
    "    if mode == 'constant':\n",
    "        map_stack = tf.stack([map_x, map_y])\n",
    "        map_indices = tf.transpose(map_stack, perm=[1, 2, 0])\n",
    "        x_ge_0 = (0.0 <= map_indices[ : , : , 0])    # [h, w]\n",
    "        x_lt_w = (map_indices[ : , : , 0] < width_f)\n",
    "        y_ge_0 = (0.0 <= map_indices[ : , : , 1])\n",
    "        y_lt_h = (map_indices[ : , : , 1] < height_f)\n",
    "        inside_boundary = tf.math.reduce_all(\n",
    "            tf.stack([x_ge_0, x_lt_w, y_ge_0, y_lt_h]), axis=0) # [h, w]\n",
    "        inside_boundary = inside_boundary[ : , : , tf.newaxis]  # [h, w, 1]\n",
    "        image_remap = tf.where(inside_boundary, image_remap, 0.0)\n",
    "\n",
    "    return image_remap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:29:56.920267Z",
     "iopub.status.busy": "2021-08-03T05:29:56.919429Z",
     "iopub.status.idle": "2021-08-03T05:29:56.921986Z",
     "shell.execute_reply": "2021-08-03T05:29:56.922438Z",
     "shell.execute_reply.started": "2021-06-15T04:13:30.526376Z"
    },
    "papermill": {
     "duration": 0.027508,
     "end_time": "2021-08-03T05:29:56.922606",
     "exception": false,
     "start_time": "2021-08-03T05:29:56.895098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "horizontal_flip = HorizontalFlip(p=0.5)\n",
    "random_brightness = RandomBrightness(max_delta=0.2, p=0.75)\n",
    "random_contrast = RandomContrast(lower=0.2, upper=0.8, p=0.75)\n",
    "optical_distortion = OpticalDistortion(\n",
    "    distort_limit=1.0, shift_limit=0.05, p=0.75)\n",
    "grid_distortion = GridDistortion(\n",
    "    num_steps=5, distort_limit=1.0, p=0.75)\n",
    "one_of_opt_grid_distortion = OneOf(\n",
    "    optical_distortion, grid_distortion, p=0.75)\n",
    "\n",
    "\n",
    "hue_saturation_value = HueSaturationValue(\n",
    "    hue_shift_limit=0.2, sat_shift_limit=0.3,\n",
    "    val_shift_limit=0.2, p=0.75)\n",
    "\n",
    "\n",
    "shift_scale_rotate = ShiftScaleRotate(\n",
    "    shift_limit=0.2, scale_limit=0.3, rotate_limit=30, p=0.75)\n",
    "\n",
    "\n",
    "cut_out = Cutout(num_cuts=1, mask_factor=0.4, p=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:29:56.974896Z",
     "iopub.status.busy": "2021-08-03T05:29:56.974032Z",
     "iopub.status.idle": "2021-08-03T05:29:56.976467Z",
     "shell.execute_reply": "2021-08-03T05:29:56.976963Z",
     "shell.execute_reply.started": "2021-06-15T04:18:31.11153Z"
    },
    "papermill": {
     "duration": 0.037855,
     "end_time": "2021-08-03T05:29:56.977138",
     "exception": false,
     "start_time": "2021-08-03T05:29:56.939283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def auto_select_accelerator():\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "        print(\"Running on TPU:\", tpu.master())\n",
    "    except ValueError:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
    "    \n",
    "    return strategy\n",
    "\n",
    "\n",
    "def build_decoder(with_labels=True, target_size=(256, 256), ext='jpg'):\n",
    "    def decode(path):\n",
    "        file_bytes = tf.io.read_file(path)\n",
    "\n",
    "        if ext == 'png':\n",
    "            img = tf.image.decode_png(file_bytes, channels=3)\n",
    "        elif ext in ['jpg', 'jpeg']:\n",
    "            img = tf.image.decode_jpeg(file_bytes, channels=3)\n",
    "        else:\n",
    "            raise ValueError(\"Image extension not supported\")\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        img = tf.image.resize(img, target_size)\n",
    "\n",
    "        return img\n",
    "    \n",
    "    def decode_with_labels(path, label):\n",
    "        return decode(path), label\n",
    "    \n",
    "    return decode_with_labels if with_labels else decode\n",
    "\n",
    "\n",
    "def build_augmenter(with_labels=True):\n",
    "   \n",
    "\n",
    "    def augment(img):\n",
    "        #img = tf.image.random_flip_left_right(img)\n",
    "        #img = tf.image.random_flip_up_down(img)\n",
    "        mask = img\n",
    "        img, _ = horizontal_flip(img, mask)\n",
    "        img, _ = random_brightness(img, mask)\n",
    "        img, _ = random_contrast(img, mask)\n",
    "        img, _ = one_of_opt_grid_distortion(img, mask)\n",
    "        img, _ = hue_saturation_value(img, mask)\n",
    "        img, _ = shift_scale_rotate(img, mask)\n",
    "        img, _ = cut_out(img, mask)\n",
    "\n",
    "        return img\n",
    "    \n",
    "    def augment_with_labels(img, label):\n",
    "        return augment(img), label\n",
    "    \n",
    "    return augment_with_labels if with_labels else augment\n",
    "\n",
    "\n",
    "def build_dataset(paths, labels=None, bsize=128, cache=True,\n",
    "                  decode_fn=None, augment_fn=None,\n",
    "                  augment=True, repeat=True, shuffle=1024, \n",
    "                  cache_dir=\"\"):\n",
    "    if cache_dir != \"\" and cache is True:\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "    \n",
    "    if decode_fn is None:\n",
    "        decode_fn = build_decoder(labels is not None)\n",
    "    \n",
    "    if augment_fn is None:\n",
    "        augment_fn = build_augmenter(labels is not None)\n",
    "    \n",
    "    AUTO = tf.data.experimental.AUTOTUNE\n",
    "    slices = paths if labels is None else (paths, labels)\n",
    "    \n",
    "    dset = tf.data.Dataset.from_tensor_slices(slices)\n",
    "    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n",
    "    dset = dset.cache(cache_dir) if cache else dset\n",
    "    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n",
    "    dset = dset.repeat() if repeat else dset\n",
    "    dset = dset.shuffle(shuffle) if shuffle else dset\n",
    "    dset = dset.batch(bsize).prefetch(AUTO)\n",
    "    \n",
    "    return dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:29:57.074755Z",
     "iopub.status.busy": "2021-08-03T05:29:57.074080Z",
     "iopub.status.idle": "2021-08-03T05:30:03.208359Z",
     "shell.execute_reply": "2021-08-03T05:30:03.207335Z",
     "shell.execute_reply.started": "2021-06-15T04:18:32.433838Z"
    },
    "papermill": {
     "duration": 6.214406,
     "end_time": "2021-08-03T05:30:03.208563",
     "exception": false,
     "start_time": "2021-08-03T05:29:56.994157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU: grpc://10.0.0.2:8470\n",
      "Running on 8 replicas\n"
     ]
    }
   ],
   "source": [
    "COMPETITION_NAME = \"siimcovid19-512-img-png-600-study-png\"\n",
    "strategy = auto_select_accelerator()\n",
    "BATCH_SIZE = strategy.num_replicas_in_sync * 16\n",
    "GCS_DS_PATH = KaggleDatasets().get_gcs_path(COMPETITION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:30:03.248928Z",
     "iopub.status.busy": "2021-08-03T05:30:03.248238Z",
     "iopub.status.idle": "2021-08-03T05:30:03.275140Z",
     "shell.execute_reply": "2021-08-03T05:30:03.275647Z",
     "shell.execute_reply.started": "2021-06-15T04:18:37.9693Z"
    },
    "papermill": {
     "duration": 0.049556,
     "end_time": "2021-08-03T05:30:03.275856",
     "exception": false,
     "start_time": "2021-08-03T05:30:03.226300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\n",
    "df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')\n",
    "label_cols = df.columns[1:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:30:03.323194Z",
     "iopub.status.busy": "2021-08-03T05:30:03.322475Z",
     "iopub.status.idle": "2021-08-03T05:30:03.363588Z",
     "shell.execute_reply": "2021-08-03T05:30:03.364141Z",
     "shell.execute_reply.started": "2021-06-15T04:18:38.001919Z"
    },
    "papermill": {
     "duration": 0.071374,
     "end_time": "2021-08-03T05:30:03.364317",
     "exception": false,
     "start_time": "2021-08-03T05:30:03.292943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gkf  = GroupKFold(n_splits = 5)\n",
    "df['fold'] = -1\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(df, groups = df.id.tolist())):\n",
    "    df.loc[val_idx, 'fold'] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:30:03.401306Z",
     "iopub.status.busy": "2021-08-03T05:30:03.400664Z",
     "iopub.status.idle": "2021-08-03T05:30:03.404844Z",
     "shell.execute_reply": "2021-08-03T05:30:03.405422Z"
    },
    "papermill": {
     "duration": 0.024075,
     "end_time": "2021-08-03T05:30:03.405598",
     "exception": false,
     "start_time": "2021-08-03T05:30:03.381523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:30:03.442967Z",
     "iopub.status.busy": "2021-08-03T05:30:03.442206Z",
     "iopub.status.idle": "2021-08-03T05:30:03.642904Z",
     "shell.execute_reply": "2021-08-03T05:30:03.643505Z"
    },
    "papermill": {
     "duration": 0.221005,
     "end_time": "2021-08-03T05:30:03.643716",
     "exception": false,
     "start_time": "2021-08-03T05:30:03.422711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SpatialAttentionModule(tf.keras.layers.Layer):\n",
    "    def __init__(self, kernel_size=3):\n",
    "        '''\n",
    "        paper: https://arxiv.org/abs/1807.06521\n",
    "        code: https://gist.github.com/innat/99888fa8065ecbf3ae2b297e5c10db70\n",
    "        '''\n",
    "        super(SpatialAttentionModule, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, kernel_size=kernel_size, \n",
    "                                            use_bias=False, \n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            strides=1, padding='same', \n",
    "                                            activation=tf.nn.relu6)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(32, kernel_size=kernel_size, \n",
    "                                            use_bias=False, \n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            strides=1, padding='same', \n",
    "                                            activation=tf.nn.relu6)\n",
    "        self.conv3 = tf.keras.layers.Conv2D(16, kernel_size=kernel_size, \n",
    "                                            use_bias=False, \n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            strides=1, padding='same', \n",
    "                                            activation=tf.nn.relu6)\n",
    "        self.conv4 = tf.keras.layers.Conv2D(1, kernel_size=kernel_size,  \n",
    "                                            use_bias=False,\n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            strides=1, padding='same', \n",
    "                                            activation=tf.math.sigmoid)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        avg_out = tf.reduce_mean(inputs, axis=3)\n",
    "        max_out = tf.reduce_max(inputs,  axis=3)\n",
    "        x = tf.stack([avg_out, max_out], axis=3) \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        return self.conv4(x)\n",
    "    \n",
    "# A custom layer\n",
    "class ChannelAttentionModule(tf.keras.layers.Layer):\n",
    "    def __init__(self, ratio=8):\n",
    "        '''\n",
    "        paper: https://arxiv.org/abs/1807.06521\n",
    "        code: https://gist.github.com/innat/99888fa8065ecbf3ae2b297e5c10db70\n",
    "        '''\n",
    "        super(ChannelAttentionModule, self).__init__()\n",
    "        self.ratio = ratio\n",
    "        self.gapavg = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.gmpmax = tf.keras.layers.GlobalMaxPooling2D()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.conv1 = tf.keras.layers.Conv2D(input_shape[-1]//self.ratio, \n",
    "                                            kernel_size=1, \n",
    "                                            strides=1, padding='same',\n",
    "                                            use_bias=True, activation=tf.nn.relu)\n",
    "    \n",
    "        self.conv2 = tf.keras.layers.Conv2D(input_shape[-1], \n",
    "                                            kernel_size=1, \n",
    "                                            strides=1, padding='same',\n",
    "                                            use_bias=True, activation=tf.nn.relu)\n",
    "        super(ChannelAttentionModule, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # compute gap and gmp pooling \n",
    "        gapavg = self.gapavg(inputs)\n",
    "        gmpmax = self.gmpmax(inputs)\n",
    "        gapavg = tf.keras.layers.Reshape((1, 1, gapavg.shape[1]))(gapavg)   \n",
    "        gmpmax = tf.keras.layers.Reshape((1, 1, gmpmax.shape[1]))(gmpmax)   \n",
    "        # forward passing to the respected layers\n",
    "        gapavg_out = self.conv2(self.conv1(gapavg))\n",
    "        gmpmax_out = self.conv2(self.conv1(gmpmax))\n",
    "        return tf.math.sigmoid(gapavg_out + gmpmax_out)\n",
    "    \n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return self.compute_output_shape(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_len = input_shape[3]\n",
    "        return (input_shape[0], output_len)\n",
    "\n",
    "# Original Src: https://github.com/bfelbo/DeepMoji/blob/master/deepmoji/attlayer.py\n",
    "# Adoped and Modified: https://www.kaggle.com/c/human-protein-atlas-image-classification/discussion/77269#454482\n",
    "class AttentionWeightedAverage2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.init = tf.keras.initializers.get('uniform')\n",
    "        super(AttentionWeightedAverage2D, self).__init__(** kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [tf.keras.layers.InputSpec(ndim=4)]\n",
    "        assert len(input_shape) == 4\n",
    "        self.W = self.add_weight(shape=(input_shape[3], 1),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=self.init)\n",
    "        self._trainable_weights = [self.W]\n",
    "        super(AttentionWeightedAverage2D, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        # computes a probability distribution over the timesteps\n",
    "        # uses 'max trick' for numerical stability\n",
    "        # reshape is done to avoid issue with Tensorflow\n",
    "        # and 2-dimensional weights\n",
    "        logits  = K.dot(x, self.W)\n",
    "        x_shape = K.shape(x)\n",
    "        logits  = K.reshape(logits, (x_shape[0], x_shape[1], x_shape[2]))\n",
    "        ai      = K.exp(logits - K.max(logits, axis=[1,2], keepdims=True))\n",
    "        \n",
    "        att_weights    = ai / (K.sum(ai, axis=[1,2], keepdims=True) + K.epsilon())\n",
    "        weighted_input = x * K.expand_dims(att_weights)\n",
    "        result         = K.sum(weighted_input, axis=[1,2])\n",
    "        return result\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return self.compute_output_shape(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_len = input_shape[3]\n",
    "        return (input_shape[0], output_len)\n",
    "\n",
    "class RANZCRClassifier(tf.keras.Model):\n",
    "    def __init__(self, dim):\n",
    "        super(RANZCRClassifier, self).__init__()\n",
    "        # Defining All Layers in __init__\n",
    "        # Layer of Block\n",
    "        self.Base  = efn.EfficientNetB5(\n",
    "            input_shape=(640,\n",
    "                         640, 3),\n",
    "            weights=None,\n",
    "            include_top=False)\n",
    "        # Keras Built-in\n",
    "        self.GAP1 = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.GAP2 = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.BAT  = tf.keras.layers.BatchNormalization()\n",
    "        self.ADD  = tf.keras.layers.Add()\n",
    "        self.AVG  = tf.keras.layers.Average()\n",
    "        self.DROP = tf.keras.layers.Dropout(rate=0.5)\n",
    "        # Customs\n",
    "        self.CAN  = ChannelAttentionModule()\n",
    "        self.SPN1 = SpatialAttentionModule()\n",
    "        self.SPN2 = SpatialAttentionModule()\n",
    "        self.AWG  = AttentionWeightedAverage2D()\n",
    "        # Tail\n",
    "        self.DENS = tf.keras.layers.Dense(512, activation=tf.nn.relu)\n",
    "        self.OUT  = tf.keras.layers.Dense(4, \n",
    "                                          activation='softmax', \n",
    "                                          #kernel_regularizer=tf.keras.regularizers.l2(0.0001),\n",
    "                                          dtype=tf.float32)\n",
    "    \n",
    "    def call(self, input_tensor, training=False):\n",
    "        # Base Inputs\n",
    "        x      = self.Base(input_tensor)\n",
    "        # Attention Modules 1\n",
    "        # Channel Attention + Spatial Attention \n",
    "        canx   = self.CAN(x)*x\n",
    "        spnx   = self.SPN1(canx)*canx\n",
    "        # Global Weighted Average Poolin\n",
    "        gapx   = self.GAP1(spnx)\n",
    "        wvgx   = self.GAP2(self.SPN2(canx))\n",
    "        gapavg = self.AVG([gapx, wvgx])\n",
    "        # Attention Modules 2\n",
    "        # Attention Weighted Average (AWG)\n",
    "        awgavg = self.AWG(x)\n",
    "        # Summation of Attentions\n",
    "        x = self.ADD([gapavg, awgavg])\n",
    "        # Tails\n",
    "        x = self.BAT(x)\n",
    "        x = self.DENS(x)\n",
    "        x  = self.DROP(x, training=training)\n",
    "        return self.OUT(x)\n",
    "    \n",
    "    # AFAIK: The most convenient method to print model.summary() in suclassed model\n",
    "    def build_graph(self):\n",
    "        x = tf.keras.layers.Input(shape=(TrainConfig.IMG_SIZE['0'],\n",
    "                                         TrainConfig.IMG_SIZE['0'],3))\n",
    "        return tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016808,
     "end_time": "2021-08-03T05:30:03.677842",
     "exception": false,
     "start_time": "2021-08-03T05:30:03.661034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " model = tf.keras.Sequential([\n",
    "            efn.EfficientNetB7(\n",
    "                input_shape=(IMSIZE[IMS], IMSIZE[IMS], 3),\n",
    "                weights='imagenet',\n",
    "                include_top=False),\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(n_labels, activation='softmax')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:30:03.717386Z",
     "iopub.status.busy": "2021-08-03T05:30:03.716747Z",
     "iopub.status.idle": "2021-08-03T05:30:03.719158Z",
     "shell.execute_reply": "2021-08-03T05:30:03.719589Z"
    },
    "papermill": {
     "duration": 0.024864,
     "end_time": "2021-08-03T05:30:03.719770",
     "exception": false,
     "start_time": "2021-08-03T05:30:03.694906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainnow = [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:30:03.771036Z",
     "iopub.status.busy": "2021-08-03T05:30:03.770335Z",
     "iopub.status.idle": "2021-08-03T08:26:12.574861Z",
     "shell.execute_reply": "2021-08-03T08:26:12.575431Z"
    },
    "papermill": {
     "duration": 10568.83863,
     "end_time": "2021-08-03T08:26:12.575663",
     "exception": false,
     "start_time": "2021-08-03T05:30:03.737033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b5_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "115515392/115515256 [==============================] - 3s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b5 (Functional) (None, 24, 24, 2048)      28513520  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 8196      \n",
      "=================================================================\n",
      "Total params: 28,521,716\n",
      "Trainable params: 28,348,980\n",
      "Non-trainable params: 172,736\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "37/37 [==============================] - 487s 8s/step - loss: 1.2034 - auc: 0.5957 - val_loss: 1.1868 - val_auc: 0.7161\n",
      "Epoch 2/20\n",
      "37/37 [==============================] - 146s 4s/step - loss: 1.0380 - auc: 0.6969 - val_loss: 0.9841 - val_auc: 0.7279\n",
      "Epoch 3/20\n",
      "37/37 [==============================] - 144s 4s/step - loss: 1.0126 - auc: 0.7129 - val_loss: 0.9635 - val_auc: 0.7747\n",
      "Epoch 4/20\n",
      "37/37 [==============================] - 147s 4s/step - loss: 0.9886 - auc: 0.7227 - val_loss: 0.9279 - val_auc: 0.7657\n",
      "Epoch 5/20\n",
      "37/37 [==============================] - 146s 4s/step - loss: 0.9514 - auc: 0.7498 - val_loss: 0.8757 - val_auc: 0.7854\n",
      "Epoch 6/20\n",
      "37/37 [==============================] - 146s 4s/step - loss: 0.9754 - auc: 0.7478 - val_loss: 1.0685 - val_auc: 0.7658\n",
      "Epoch 7/20\n",
      "37/37 [==============================] - 157s 4s/step - loss: 0.9523 - auc: 0.7600 - val_loss: 1.0059 - val_auc: 0.7622\n",
      "Epoch 8/20\n",
      "37/37 [==============================] - 161s 4s/step - loss: 0.9366 - auc: 0.7552 - val_loss: 1.0165 - val_auc: 0.7793\n",
      "Epoch 9/20\n",
      "37/37 [==============================] - 158s 4s/step - loss: 0.9296 - auc: 0.7771 - val_loss: 0.8930 - val_auc: 0.8045\n",
      "Epoch 10/20\n",
      "37/37 [==============================] - 160s 4s/step - loss: 0.8916 - auc: 0.7862 - val_loss: 0.8682 - val_auc: 0.8114\n",
      "Epoch 11/20\n",
      "37/37 [==============================] - 142s 4s/step - loss: 0.9027 - auc: 0.7937 - val_loss: 0.8433 - val_auc: 0.8132\n",
      "Epoch 12/20\n",
      "37/37 [==============================] - 143s 4s/step - loss: 0.8714 - auc: 0.7982 - val_loss: 0.8428 - val_auc: 0.8145\n",
      "Epoch 13/20\n",
      "37/37 [==============================] - 138s 4s/step - loss: 0.8525 - auc: 0.8083 - val_loss: 0.8518 - val_auc: 0.8139\n",
      "Epoch 14/20\n",
      "37/37 [==============================] - 166s 5s/step - loss: 0.8667 - auc: 0.7996 - val_loss: 0.8553 - val_auc: 0.8149\n",
      "Epoch 15/20\n",
      "37/37 [==============================] - 160s 4s/step - loss: 0.8573 - auc: 0.8164 - val_loss: 0.8451 - val_auc: 0.8151\n",
      "Epoch 16/20\n",
      "37/37 [==============================] - 156s 4s/step - loss: 0.8419 - auc: 0.8125 - val_loss: 0.8387 - val_auc: 0.8164\n",
      "Epoch 17/20\n",
      "37/37 [==============================] - 145s 4s/step - loss: 0.8748 - auc: 0.8031 - val_loss: 0.8362 - val_auc: 0.8165\n",
      "Epoch 18/20\n",
      "37/37 [==============================] - 143s 4s/step - loss: 0.8819 - auc: 0.8051 - val_loss: 0.8345 - val_auc: 0.8167\n",
      "Epoch 19/20\n",
      "37/37 [==============================] - 144s 4s/step - loss: 0.8681 - auc: 0.8080 - val_loss: 0.8337 - val_auc: 0.8167\n",
      "Epoch 20/20\n",
      "37/37 [==============================] - 149s 4s/step - loss: 0.8605 - auc: 0.8102 - val_loss: 0.8319 - val_auc: 0.8169\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b5 (Functional) (None, 24, 24, 2048)      28513520  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 8196      \n",
      "=================================================================\n",
      "Total params: 28,521,716\n",
      "Trainable params: 28,348,980\n",
      "Non-trainable params: 172,736\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "37/37 [==============================] - 417s 6s/step - loss: 1.1946 - auc_1: 0.5991 - val_loss: 1.4409 - val_auc_1: 0.6945\n",
      "Epoch 2/20\n",
      "37/37 [==============================] - 145s 4s/step - loss: 1.0266 - auc_1: 0.7029 - val_loss: 1.0864 - val_auc_1: 0.7656\n",
      "Epoch 3/20\n",
      "37/37 [==============================] - 145s 4s/step - loss: 1.0262 - auc_1: 0.7040 - val_loss: 1.2821 - val_auc_1: 0.7504\n",
      "Epoch 4/20\n",
      "37/37 [==============================] - 155s 4s/step - loss: 0.9881 - auc_1: 0.7385 - val_loss: 1.0432 - val_auc_1: 0.7663\n",
      "Epoch 5/20\n",
      "37/37 [==============================] - 144s 4s/step - loss: 0.9578 - auc_1: 0.7461 - val_loss: 1.0325 - val_auc_1: 0.7549\n",
      "Epoch 6/20\n",
      "37/37 [==============================] - 145s 4s/step - loss: 0.9489 - auc_1: 0.7593 - val_loss: 0.9996 - val_auc_1: 0.7746\n",
      "Epoch 7/20\n",
      "37/37 [==============================] - 147s 4s/step - loss: 0.9260 - auc_1: 0.7659 - val_loss: 1.1320 - val_auc_1: 0.7631\n",
      "Epoch 8/20\n",
      "37/37 [==============================] - 155s 4s/step - loss: 0.9114 - auc_1: 0.7703 - val_loss: 0.9912 - val_auc_1: 0.7893\n",
      "Epoch 9/20\n",
      "37/37 [==============================] - 146s 4s/step - loss: 0.9235 - auc_1: 0.7667 - val_loss: 1.0968 - val_auc_1: 0.7707\n",
      "Epoch 10/20\n",
      "37/37 [==============================] - 163s 4s/step - loss: 0.9072 - auc_1: 0.7669 - val_loss: 0.9259 - val_auc_1: 0.7916\n",
      "Epoch 11/20\n",
      "37/37 [==============================] - 142s 4s/step - loss: 0.8921 - auc_1: 0.7803 - val_loss: 0.9553 - val_auc_1: 0.7907\n",
      "Epoch 12/20\n",
      "37/37 [==============================] - 163s 4s/step - loss: 0.8977 - auc_1: 0.7806 - val_loss: 1.0183 - val_auc_1: 0.7894\n",
      "Epoch 13/20\n",
      "37/37 [==============================] - 156s 4s/step - loss: 0.8973 - auc_1: 0.7844 - val_loss: 0.9535 - val_auc_1: 0.7915\n",
      "Epoch 14/20\n",
      "37/37 [==============================] - 162s 4s/step - loss: 0.8731 - auc_1: 0.8038 - val_loss: 0.9732 - val_auc_1: 0.7914\n",
      "Epoch 15/20\n",
      "37/37 [==============================] - 165s 4s/step - loss: 0.8467 - auc_1: 0.8134 - val_loss: 0.9457 - val_auc_1: 0.7984\n",
      "Epoch 16/20\n",
      "37/37 [==============================] - 164s 5s/step - loss: 0.8201 - auc_1: 0.8274 - val_loss: 0.9005 - val_auc_1: 0.8072\n",
      "Epoch 17/20\n",
      "37/37 [==============================] - 145s 4s/step - loss: 0.8260 - auc_1: 0.8188 - val_loss: 0.8971 - val_auc_1: 0.8068\n",
      "Epoch 18/20\n",
      "37/37 [==============================] - 143s 4s/step - loss: 0.8516 - auc_1: 0.8143 - val_loss: 0.9161 - val_auc_1: 0.8045\n",
      "Epoch 19/20\n",
      "37/37 [==============================] - 161s 4s/step - loss: 0.8103 - auc_1: 0.8309 - val_loss: 0.9066 - val_auc_1: 0.8058\n",
      "Epoch 20/20\n",
      "37/37 [==============================] - 160s 4s/step - loss: 0.8064 - auc_1: 0.8356 - val_loss: 0.9059 - val_auc_1: 0.8046\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b5 (Functional) (None, 24, 24, 2048)      28513520  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 8196      \n",
      "=================================================================\n",
      "Total params: 28,521,716\n",
      "Trainable params: 28,348,980\n",
      "Non-trainable params: 172,736\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "37/37 [==============================] - 416s 6s/step - loss: 1.2054 - auc_2: 0.5951 - val_loss: 1.1354 - val_auc_2: 0.7236\n",
      "Epoch 2/20\n",
      "37/37 [==============================] - 147s 4s/step - loss: 1.0488 - auc_2: 0.6727 - val_loss: 0.9879 - val_auc_2: 0.7653\n",
      "Epoch 3/20\n",
      "37/37 [==============================] - 141s 4s/step - loss: 1.0125 - auc_2: 0.7072 - val_loss: 0.9536 - val_auc_2: 0.7888\n",
      "Epoch 4/20\n",
      "37/37 [==============================] - 141s 4s/step - loss: 1.0074 - auc_2: 0.7130 - val_loss: 1.0592 - val_auc_2: 0.7868\n",
      "Epoch 5/20\n",
      "37/37 [==============================] - 159s 4s/step - loss: 0.9884 - auc_2: 0.7312 - val_loss: 0.9221 - val_auc_2: 0.7877\n",
      "Epoch 6/20\n",
      "37/37 [==============================] - 148s 4s/step - loss: 0.9859 - auc_2: 0.7456 - val_loss: 1.0463 - val_auc_2: 0.7785\n",
      "Epoch 7/20\n",
      "37/37 [==============================] - 161s 4s/step - loss: 0.9607 - auc_2: 0.7565 - val_loss: 0.9684 - val_auc_2: 0.7785\n",
      "Epoch 8/20\n",
      "37/37 [==============================] - 161s 4s/step - loss: 0.9558 - auc_2: 0.7508 - val_loss: 1.1575 - val_auc_2: 0.7819\n",
      "Epoch 9/20\n",
      "37/37 [==============================] - 159s 4s/step - loss: 0.9374 - auc_2: 0.7644 - val_loss: 0.8648 - val_auc_2: 0.8094\n",
      "Epoch 10/20\n",
      "37/37 [==============================] - 143s 4s/step - loss: 0.9048 - auc_2: 0.7853 - val_loss: 0.8536 - val_auc_2: 0.8119\n",
      "Epoch 11/20\n",
      "37/37 [==============================] - 138s 4s/step - loss: 0.8937 - auc_2: 0.7937 - val_loss: 0.8496 - val_auc_2: 0.8150\n",
      "Epoch 12/20\n",
      "37/37 [==============================] - 146s 4s/step - loss: 0.8821 - auc_2: 0.7958 - val_loss: 0.8410 - val_auc_2: 0.8158\n",
      "Epoch 13/20\n",
      "37/37 [==============================] - 138s 4s/step - loss: 0.8920 - auc_2: 0.8013 - val_loss: 0.8335 - val_auc_2: 0.8161\n",
      "Epoch 14/20\n",
      "37/37 [==============================] - 143s 4s/step - loss: 0.8523 - auc_2: 0.8135 - val_loss: 0.8493 - val_auc_2: 0.8144\n",
      "Epoch 15/20\n",
      "37/37 [==============================] - 156s 4s/step - loss: 0.8515 - auc_2: 0.8120 - val_loss: 0.8265 - val_auc_2: 0.8205\n",
      "Epoch 16/20\n",
      "37/37 [==============================] - 144s 4s/step - loss: 0.8505 - auc_2: 0.8114 - val_loss: 0.8288 - val_auc_2: 0.8206\n",
      "Epoch 17/20\n",
      "37/37 [==============================] - 162s 4s/step - loss: 0.8575 - auc_2: 0.8071 - val_loss: 0.8295 - val_auc_2: 0.8202\n",
      "Epoch 18/20\n",
      "37/37 [==============================] - 156s 4s/step - loss: 0.8448 - auc_2: 0.8208 - val_loss: 0.8408 - val_auc_2: 0.8158\n",
      "Epoch 19/20\n",
      "37/37 [==============================] - 161s 4s/step - loss: 0.8629 - auc_2: 0.8123 - val_loss: 0.8366 - val_auc_2: 0.8172\n",
      "Epoch 20/20\n",
      "37/37 [==============================] - 160s 4s/step - loss: 0.8576 - auc_2: 0.8164 - val_loss: 0.8357 - val_auc_2: 0.8183\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    if i in trainnow:\n",
    "\n",
    "        valid_paths = GCS_DS_PATH + '/study/' + df[df['fold'] == i]['id'] + '.png' #\"/train/\"\n",
    "        train_paths = GCS_DS_PATH + '/study/' + df[df['fold'] != i]['id'] + '.png' #\"/train/\" \n",
    "        valid_labels = df[df['fold'] == i][label_cols].values\n",
    "        train_labels = df[df['fold'] != i][label_cols].values\n",
    "\n",
    "        IMSIZE = (224, 240, 260, 300, 380, 456, 528, 768)\n",
    "        IMS = 7\n",
    "\n",
    "        decoder = build_decoder(with_labels=True, target_size=(IMSIZE[IMS], IMSIZE[IMS]), ext='png')\n",
    "        test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[IMS], IMSIZE[IMS]),ext='png')\n",
    "\n",
    "        train_dataset = build_dataset(\n",
    "            train_paths, train_labels, bsize=BATCH_SIZE, decode_fn=decoder\n",
    "        )\n",
    "\n",
    "        valid_dataset = build_dataset(\n",
    "            valid_paths, valid_labels, bsize=BATCH_SIZE, decode_fn=decoder,\n",
    "            repeat=False, shuffle=False, augment=False\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            n_labels = train_labels.shape[1]\n",
    "        except:\n",
    "            n_labels = 1\n",
    "\n",
    "        with strategy.scope():\n",
    "\n",
    "            model = tf.keras.Sequential([\n",
    "                efn.EfficientNetB5(\n",
    "                    input_shape=(IMSIZE[IMS], IMSIZE[IMS], 3),\n",
    "                    weights='imagenet',\n",
    "                    include_top=False),\n",
    "                tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                tf.keras.layers.Dropout(.1),\n",
    "                tf.keras.layers.Dense(n_labels, activation='softmax')\n",
    "            ])\n",
    "\n",
    "\n",
    "            model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=[tf.keras.metrics.AUC(multi_label=True)])\n",
    "\n",
    "            model.summary()\n",
    "\n",
    "\n",
    "        steps_per_epoch = train_paths.shape[0] // BATCH_SIZE\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            f'model{i}.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "        lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", patience=3, min_lr=1e-6, mode='min')\n",
    "\n",
    "        history = model.fit(\n",
    "            train_dataset, \n",
    "            epochs=20,\n",
    "            verbose=1,\n",
    "            callbacks=[checkpoint, lr_reducer],\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_data=valid_dataset)\n",
    "\n",
    "        hist_df = pd.DataFrame(history.history)\n",
    "        hist_df.to_csv(f'history{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.758511,
     "end_time": "2021-08-03T08:26:14.090895",
     "exception": false,
     "start_time": "2021-08-03T08:26:13.332384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10605.349413,
   "end_time": "2021-08-03T08:26:18.411468",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-03T05:29:33.062055",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
