{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T05:25:22.735649Z",
     "iopub.status.busy": "2022-11-29T05:25:22.734658Z",
     "iopub.status.idle": "2022-11-29T05:25:34.445239Z",
     "shell.execute_reply": "2022-11-29T05:25:34.443454Z",
     "shell.execute_reply.started": "2022-11-29T05:25:22.735601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.12.1\n",
      "transformers.__version__: 4.20.1\n",
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from transformers import DataCollatorWithPadding\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T05:25:34.448836Z",
     "iopub.status.busy": "2022-11-29T05:25:34.447967Z",
     "iopub.status.idle": "2022-11-29T05:25:39.145411Z",
     "shell.execute_reply": "2022-11-29T05:25:39.144072Z",
     "shell.execute_reply.started": "2022-11-29T05:25:34.448781Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG0:\n",
    "    model = \"microsoft/deberta-v3-base\"\n",
    "    path = \"/kaggle/input/fb3-single-pytorch-model-train/20221128-161025-deberta-v3-base/\"\n",
    "    base = \"../input/fb3models/microsoft-deberta-v3-base/\"\n",
    "    config_path = base + \"config/config.json\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base + 'tokenizer/')\n",
    "    gradient_checkpointing=False\n",
    "    batch_size=24\n",
    "    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "    seed=42\n",
    "    n_fold=4\n",
    "    trn_fold=list(range(n_fold))\n",
    "    num_workers=4\n",
    "    weight = 1.0\n",
    "    \n",
    "class CFG1:\n",
    "    model = \"microsoft/deberta-v3-base\"\n",
    "    path = \"../input/0911-deberta-v3-base/\"\n",
    "    base = \"../input/fb3models/microsoft-deberta-v3-base/\"\n",
    "    config_path = base + \"config/config.json\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base + 'tokenizer/')\n",
    "    gradient_checkpointing=False\n",
    "    batch_size=24\n",
    "    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "    seed=42\n",
    "    n_fold=10\n",
    "    trn_fold=list(range(n_fold))\n",
    "    num_workers=4\n",
    "    weight = 1.0\n",
    "\n",
    "    \n",
    "class CFG2:\n",
    "    model = \"microsoft/deberta-v3-large\"\n",
    "    path = \"../input/0911-deberta-v3-large/\"\n",
    "    base = \"../input/fb3models/microsoft-deberta-v3-large/\"\n",
    "    config_path = base + \"config/config.json\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base + 'tokenizer/')\n",
    "    gradient_checkpointing=False\n",
    "    batch_size=16\n",
    "    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "    seed=42\n",
    "    n_fold=10\n",
    "    trn_fold=list(range(n_fold))\n",
    "    num_workers=4\n",
    "    weight = 1.0\n",
    "    \n",
    "class CFG3:\n",
    "    model = \"microsoft/deberta-v2-xlarge\"\n",
    "    path = \"../input/0911-deberta-v2-xlarge/\"\n",
    "    base = \"../input/fb3models/microsoft-deberta-v2-xlarge/\"\n",
    "    config_path = base + \"config/config.json\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base + 'tokenizer/')\n",
    "    gradient_checkpointing=False\n",
    "    batch_size=4\n",
    "    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "    seed=42\n",
    "    n_fold=10\n",
    "    trn_fold=list(range(n_fold))\n",
    "    num_workers=4\n",
    "    weight = 1.0\n",
    "\n",
    "class CFG4:\n",
    "    model = \"microsoft/deberta-v3-base\"\n",
    "    path = \"../input/0913-deberta-v3-base-fgm/\"\n",
    "    base = \"../input/fb3models/microsoft-deberta-v3-base/\"\n",
    "    config_path = base + \"config/config.json\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base + 'tokenizer/')\n",
    "    gradient_checkpointing=False\n",
    "    batch_size=24\n",
    "    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "    seed=42\n",
    "    n_fold=10\n",
    "    trn_fold=list(range(n_fold))\n",
    "    num_workers=4\n",
    "    weight = 1.0\n",
    "    \n",
    "class CFG5:\n",
    "    model = \"microsoft/deberta-v3-large\"\n",
    "    path = \"../input/0914-deberta-v3-large-fgm/\"\n",
    "    base = \"../input/fb3models/microsoft-deberta-v3-large/\"\n",
    "    config_path = base + \"config/config.json\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base + 'tokenizer/')\n",
    "    gradient_checkpointing=False\n",
    "    batch_size=16\n",
    "    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "    seed=42\n",
    "    n_fold=10\n",
    "    trn_fold=list(range(n_fold))\n",
    "    num_workers=4\n",
    "    weight = 1.0\n",
    "    \n",
    "class CFG6:\n",
    "    model = \"microsoft/deberta-v2-xlarge\"\n",
    "    path = \"../input/0919-deberta-v2-xlarge/\"\n",
    "    base = \"../input/fb3models/microsoft-deberta-v2-xlarge/\"\n",
    "    config_path = base + \"config/config.json\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base + 'tokenizer/')\n",
    "    gradient_checkpointing=False\n",
    "    batch_size=4\n",
    "    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "    seed=42\n",
    "    n_fold=10\n",
    "    trn_fold=list(range(n_fold))\n",
    "    num_workers=4\n",
    "    weight = 1.0\n",
    "    \n",
    "class CFG7:\n",
    "    model = \"microsoft/deberta-v2-xlarge-mnli\"\n",
    "    path = \"../input/0919-deberta-v2-xlarge-mnli/\"\n",
    "    base = \"../input/fb3models/microsoft-deberta-v2-xlarge/\"\n",
    "    config_path = base + \"config/config.json\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base + 'tokenizer/')\n",
    "    gradient_checkpointing=False\n",
    "    batch_size=4\n",
    "    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "    seed=42\n",
    "    n_fold=10\n",
    "    trn_fold=list(range(n_fold))\n",
    "    num_workers=4\n",
    "    weight = 1.0\n",
    "    \n",
    "class CFG8:\n",
    "    model = \"microsoft/deberta-v3-large\"\n",
    "    path = \"../input/0925-deberta-v3-large-unscale/\"\n",
    "    base = \"../input/fb3models/microsoft-deberta-v3-large/\"\n",
    "    config_path = base + \"config/config.json\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base + 'tokenizer/')\n",
    "    gradient_checkpointing=False\n",
    "    batch_size=8\n",
    "    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "    seed=42\n",
    "    n_fold=10\n",
    "    trn_fold=list(range(n_fold))\n",
    "    num_workers=4\n",
    "    weight = 1.0\n",
    "    \n",
    "class CFG9:\n",
    "    model = \"microsoft/deberta-v3-large\"\n",
    "    path = \"../input/0926-deberta-v3-large-unscale/\"\n",
    "    base = \"../input/fb3models/microsoft-deberta-v3-large/\"\n",
    "    config_path = base + \"config/config.json\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base + 'tokenizer/')\n",
    "    gradient_checkpointing=False\n",
    "    batch_size=8\n",
    "    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "    seed=42\n",
    "    n_fold=10\n",
    "    trn_fold=list(range(n_fold))\n",
    "    num_workers=4\n",
    "    weight = 1.0\n",
    "    \n",
    "class CFG10:\n",
    "    model = \"microsoft/deberta-v3-large\"\n",
    "    path = \"../input/0927-deberta-v3-large-unscale/\"\n",
    "    base = \"../input/fb3models/microsoft-deberta-v3-large/\"\n",
    "    config_path = base + \"config/config.json\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base + 'tokenizer/')\n",
    "    gradient_checkpointing=False\n",
    "    batch_size=8\n",
    "    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "    seed=42\n",
    "    n_fold=10\n",
    "    trn_fold=list(range(n_fold))\n",
    "    num_workers=4\n",
    "    weight = 1.0\n",
    "    \n",
    "CFG_list = [CFG0, CFG1, CFG2, CFG3, CFG4, CFG5, CFG6, CFG7, CFG8, CFG9, CFG10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T05:25:39.148178Z",
     "iopub.status.busy": "2022-11-29T05:25:39.147353Z",
     "iopub.status.idle": "2022-11-29T05:25:39.168035Z",
     "shell.execute_reply": "2022-11-29T05:25:39.166338Z",
     "shell.execute_reply.started": "2022-11-29T05:25:39.148126Z"
    },
    "papermill": {
     "duration": 0.019843,
     "end_time": "2022-09-08T02:59:41.626234",
     "exception": false,
     "start_time": "2022-09-08T02:59:41.606391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def MCRMSE(y_trues, y_preds):\n",
    "    scores = []\n",
    "    idxes = y_trues.shape[1]\n",
    "    for i in range(idxes):\n",
    "        y_true = y_trues[:,i]\n",
    "        y_pred = y_preds[:,i]\n",
    "        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n",
    "        scores.append(score)\n",
    "    mcrmse_score = np.mean(scores)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "def get_score(y_trues, y_preds):\n",
    "    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "def get_logger(filename='inference'):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T05:27:51.608584Z",
     "iopub.status.busy": "2022-11-29T05:27:51.608006Z",
     "iopub.status.idle": "2022-11-29T05:27:51.920632Z",
     "shell.execute_reply": "2022-11-29T05:27:51.919124Z",
     "shell.execute_reply.started": "2022-11-29T05:27:51.608537Z"
    },
    "papermill": {
     "duration": 0.245898,
     "end_time": "2022-09-08T02:59:41.883068",
     "exception": false,
     "start_time": "2022-09-08T02:59:41.63717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model: microsoft/deberta-v3-base Score: 0.4535  Scores: [0.4819319573874839, 0.4463208426293747, 0.4160686326130345, 0.45453883048349986, 0.473678143709784, 0.44875544473089224]\n",
      "Model: microsoft/deberta-v3-base Score: 0.4595  Scores: [0.4933251819697969, 0.4502769020486089, 0.4195917881022107, 0.4616825211894006, 0.47917149434101597, 0.4531265111349054]\n",
      "Model: microsoft/deberta-v3-large Score: 0.4553  Scores: [0.4825651519863177, 0.4513317839900914, 0.41614874855477335, 0.4570395272138213, 0.474128019225801, 0.450479894985895]\n",
      "Model: microsoft/deberta-v2-xlarge Score: 0.4604  Scores: [0.4917071615090481, 0.45037595310481654, 0.41863623824576296, 0.4599613387949261, 0.48437918084586873, 0.45728281977714613]\n",
      "Model: microsoft/deberta-v3-base Score: 0.4590  Scores: [0.4927071121286561, 0.449759196538063, 0.41900989606208666, 0.46100316932040336, 0.47875430698135113, 0.45294619259154856]\n",
      "Model: microsoft/deberta-v3-large Score: 0.4564  Scores: [0.4858750389533292, 0.4521088407160486, 0.4164558873635683, 0.4586287433972931, 0.47318859800392843, 0.451933138136932]\n",
      "Model: microsoft/deberta-v2-xlarge Score: 0.4666  Scores: [0.501914612260471, 0.45408436833576316, 0.43047529406905505, 0.46687013136512123, 0.48929816209207166, 0.45724453846394597]\n",
      "Model: microsoft/deberta-v2-xlarge-mnli Score: 0.4675  Scores: [0.49765214409591746, 0.45645117314928074, 0.43279234487694745, 0.46864751982203684, 0.4879833196863009, 0.46167228651427644]\n",
      "Model: microsoft/deberta-v3-large Score: 0.4616  Scores: [0.49412652402103946, 0.4520150460405901, 0.4283603340781925, 0.46482874397322443, 0.47956959378121433, 0.4506082838059614]\n",
      "Model: microsoft/deberta-v3-large Score: 0.4548  Scores: [0.48417351958466004, 0.44964941973664024, 0.4196980996019064, 0.45464137251257936, 0.4730027471092606, 0.4478303709836742]\n",
      "Model: microsoft/deberta-v3-large Score: 0.4569  Scores: [0.4881251563991662, 0.45350791183634237, 0.4167653497073674, 0.45556291682415684, 0.4730988790374933, 0.4544346186864903]\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# oof\n",
    "# ====================================================\n",
    "repeats = ['text_id','full_text','cohesion','syntax','vocabulary','phraseology','grammar','conventions','fold']\n",
    "all_oofs = []\n",
    "for CFG in CFG_list:\n",
    "    oof_df = pd.read_pickle(CFG.path+'oof_df.pkl').sort_values(\"text_id\").reset_index(drop=True)\n",
    "    all_oofs.append(oof_df.drop(columns = repeats))\n",
    "    labels = oof_df[CFG.target_cols].values\n",
    "    preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n",
    "    score, scores = get_score(labels, preds)\n",
    "    LOGGER.info(f'Model: {CFG.model} Score: {score:<.4f}  Scores: {scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T05:27:58.891098Z",
     "iopub.status.busy": "2022-11-29T05:27:58.890041Z",
     "iopub.status.idle": "2022-11-29T05:27:58.898265Z",
     "shell.execute_reply": "2022-11-29T05:27:58.896688Z",
     "shell.execute_reply.started": "2022-11-29T05:27:58.891046Z"
    }
   },
   "outputs": [],
   "source": [
    "features = np.concatenate(all_oofs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T05:28:11.264765Z",
     "iopub.status.busy": "2022-11-29T05:28:11.264152Z",
     "iopub.status.idle": "2022-11-29T05:28:11.276959Z",
     "shell.execute_reply": "2022-11-29T05:28:11.274879Z",
     "shell.execute_reply.started": "2022-11-29T05:28:11.264696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3911, 66)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T05:29:05.379580Z",
     "iopub.status.busy": "2022-11-29T05:29:05.379127Z",
     "iopub.status.idle": "2022-11-29T05:29:05.391088Z",
     "shell.execute_reply": "2022-11-29T05:29:05.389210Z",
     "shell.execute_reply.started": "2022-11-29T05:29:05.379545Z"
    }
   },
   "outputs": [],
   "source": [
    "feats =[f\"col{i}\" for i in range(features.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T05:29:18.910122Z",
     "iopub.status.busy": "2022-11-29T05:29:18.909577Z",
     "iopub.status.idle": "2022-11-29T05:29:19.003267Z",
     "shell.execute_reply": "2022-11-29T05:29:19.001239Z",
     "shell.execute_reply.started": "2022-11-29T05:29:18.910082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>fold</th>\n",
       "      <th>pred_cohesion</th>\n",
       "      <th>...</th>\n",
       "      <th>col56</th>\n",
       "      <th>col57</th>\n",
       "      <th>col58</th>\n",
       "      <th>col59</th>\n",
       "      <th>col60</th>\n",
       "      <th>col61</th>\n",
       "      <th>col62</th>\n",
       "      <th>col63</th>\n",
       "      <th>col64</th>\n",
       "      <th>col65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.980735</td>\n",
       "      <td>...</td>\n",
       "      <td>3.125459</td>\n",
       "      <td>3.190478</td>\n",
       "      <td>3.196349</td>\n",
       "      <td>2.759905</td>\n",
       "      <td>2.980735</td>\n",
       "      <td>2.835174</td>\n",
       "      <td>3.170818</td>\n",
       "      <td>3.228327</td>\n",
       "      <td>3.237290</td>\n",
       "      <td>2.741138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.617372</td>\n",
       "      <td>...</td>\n",
       "      <td>2.964808</td>\n",
       "      <td>2.631736</td>\n",
       "      <td>2.597791</td>\n",
       "      <td>2.538102</td>\n",
       "      <td>2.617372</td>\n",
       "      <td>2.424425</td>\n",
       "      <td>2.787720</td>\n",
       "      <td>2.749041</td>\n",
       "      <td>2.504684</td>\n",
       "      <td>2.660148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.927259</td>\n",
       "      <td>...</td>\n",
       "      <td>3.102823</td>\n",
       "      <td>2.969282</td>\n",
       "      <td>3.015122</td>\n",
       "      <td>2.955758</td>\n",
       "      <td>2.927259</td>\n",
       "      <td>2.872589</td>\n",
       "      <td>3.009427</td>\n",
       "      <td>2.989432</td>\n",
       "      <td>3.138277</td>\n",
       "      <td>3.040892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.609747</td>\n",
       "      <td>...</td>\n",
       "      <td>4.027184</td>\n",
       "      <td>3.896751</td>\n",
       "      <td>3.941613</td>\n",
       "      <td>3.769177</td>\n",
       "      <td>3.609747</td>\n",
       "      <td>3.580019</td>\n",
       "      <td>3.711982</td>\n",
       "      <td>3.699846</td>\n",
       "      <td>3.702923</td>\n",
       "      <td>3.738539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.433649</td>\n",
       "      <td>...</td>\n",
       "      <td>2.649640</td>\n",
       "      <td>2.740055</td>\n",
       "      <td>2.587462</td>\n",
       "      <td>2.310569</td>\n",
       "      <td>2.433649</td>\n",
       "      <td>2.372660</td>\n",
       "      <td>2.812410</td>\n",
       "      <td>2.606741</td>\n",
       "      <td>2.464537</td>\n",
       "      <td>2.190254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3906</th>\n",
       "      <td>FFD29828A873</td>\n",
       "      <td>I believe using cellphones in class for educat...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5</td>\n",
       "      <td>2.676923</td>\n",
       "      <td>...</td>\n",
       "      <td>2.847502</td>\n",
       "      <td>2.849612</td>\n",
       "      <td>2.645768</td>\n",
       "      <td>2.241242</td>\n",
       "      <td>2.676923</td>\n",
       "      <td>2.744390</td>\n",
       "      <td>2.670801</td>\n",
       "      <td>2.791678</td>\n",
       "      <td>2.739287</td>\n",
       "      <td>2.175364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>FFD9A83B0849</td>\n",
       "      <td>Working alone, students do not have to argue w...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.742900</td>\n",
       "      <td>...</td>\n",
       "      <td>3.556110</td>\n",
       "      <td>3.405059</td>\n",
       "      <td>3.109952</td>\n",
       "      <td>3.174611</td>\n",
       "      <td>3.742900</td>\n",
       "      <td>3.415915</td>\n",
       "      <td>3.511111</td>\n",
       "      <td>3.421340</td>\n",
       "      <td>3.148365</td>\n",
       "      <td>3.035161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>FFDC4011AC9C</td>\n",
       "      <td>\"A problem is a chance for you to do your best...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3.040246</td>\n",
       "      <td>...</td>\n",
       "      <td>3.295261</td>\n",
       "      <td>3.373523</td>\n",
       "      <td>3.541609</td>\n",
       "      <td>2.943113</td>\n",
       "      <td>3.040246</td>\n",
       "      <td>3.022676</td>\n",
       "      <td>3.148523</td>\n",
       "      <td>3.220136</td>\n",
       "      <td>3.445342</td>\n",
       "      <td>2.865385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>FFE16D704B16</td>\n",
       "      <td>Many people disagree with Albert Schweitzer's ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5</td>\n",
       "      <td>3.753411</td>\n",
       "      <td>...</td>\n",
       "      <td>3.922573</td>\n",
       "      <td>3.876611</td>\n",
       "      <td>3.640419</td>\n",
       "      <td>3.903100</td>\n",
       "      <td>3.753411</td>\n",
       "      <td>3.827273</td>\n",
       "      <td>3.852465</td>\n",
       "      <td>3.807061</td>\n",
       "      <td>3.847542</td>\n",
       "      <td>3.894267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>FFED00D6E0BD</td>\n",
       "      <td>Do you think that failure is the main thing fo...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3.329528</td>\n",
       "      <td>...</td>\n",
       "      <td>3.447617</td>\n",
       "      <td>3.222591</td>\n",
       "      <td>2.972023</td>\n",
       "      <td>3.171258</td>\n",
       "      <td>3.329528</td>\n",
       "      <td>3.070874</td>\n",
       "      <td>3.449126</td>\n",
       "      <td>3.252110</td>\n",
       "      <td>2.981187</td>\n",
       "      <td>3.246317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3911 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           text_id                                          full_text  \\\n",
       "0     0016926B079C  I think that students would benefit from learn...   \n",
       "1     0022683E9EA5  When a problem is a change you have to let it ...   \n",
       "2     00299B378633  Dear, Principal\\n\\nIf u change the school poli...   \n",
       "3     003885A45F42  The best time in life is when you become yours...   \n",
       "4     0049B1DF5CCC  Small act of kindness can impact in other peop...   \n",
       "...            ...                                                ...   \n",
       "3906  FFD29828A873  I believe using cellphones in class for educat...   \n",
       "3907  FFD9A83B0849  Working alone, students do not have to argue w...   \n",
       "3908  FFDC4011AC9C  \"A problem is a chance for you to do your best...   \n",
       "3909  FFE16D704B16  Many people disagree with Albert Schweitzer's ...   \n",
       "3910  FFED00D6E0BD  Do you think that failure is the main thing fo...   \n",
       "\n",
       "      cohesion  syntax  vocabulary  phraseology  grammar  conventions  fold  \\\n",
       "0          3.5     3.5         3.0          3.0      4.0          3.0     9   \n",
       "1          2.5     2.5         3.0          2.0      2.0          2.5     2   \n",
       "2          3.0     3.5         3.0          3.0      3.0          2.5     1   \n",
       "3          4.5     4.5         4.5          4.5      4.0          5.0     1   \n",
       "4          2.5     3.0         3.0          3.0      2.5          2.5     0   \n",
       "...        ...     ...         ...          ...      ...          ...   ...   \n",
       "3906       2.5     3.0         3.0          3.5      2.5          2.5     5   \n",
       "3907       4.0     4.0         4.0          4.0      3.5          3.0     3   \n",
       "3908       2.5     3.0         3.0          3.0      3.5          3.0     8   \n",
       "3909       4.0     4.5         4.5          4.0      4.5          4.5     5   \n",
       "3910       3.5     2.5         3.5          3.0      3.0          3.5     8   \n",
       "\n",
       "      pred_cohesion  ...     col56     col57     col58     col59     col60  \\\n",
       "0          2.980735  ...  3.125459  3.190478  3.196349  2.759905  2.980735   \n",
       "1          2.617372  ...  2.964808  2.631736  2.597791  2.538102  2.617372   \n",
       "2          2.927259  ...  3.102823  2.969282  3.015122  2.955758  2.927259   \n",
       "3          3.609747  ...  4.027184  3.896751  3.941613  3.769177  3.609747   \n",
       "4          2.433649  ...  2.649640  2.740055  2.587462  2.310569  2.433649   \n",
       "...             ...  ...       ...       ...       ...       ...       ...   \n",
       "3906       2.676923  ...  2.847502  2.849612  2.645768  2.241242  2.676923   \n",
       "3907       3.742900  ...  3.556110  3.405059  3.109952  3.174611  3.742900   \n",
       "3908       3.040246  ...  3.295261  3.373523  3.541609  2.943113  3.040246   \n",
       "3909       3.753411  ...  3.922573  3.876611  3.640419  3.903100  3.753411   \n",
       "3910       3.329528  ...  3.447617  3.222591  2.972023  3.171258  3.329528   \n",
       "\n",
       "         col61     col62     col63     col64     col65  \n",
       "0     2.835174  3.170818  3.228327  3.237290  2.741138  \n",
       "1     2.424425  2.787720  2.749041  2.504684  2.660148  \n",
       "2     2.872589  3.009427  2.989432  3.138277  3.040892  \n",
       "3     3.580019  3.711982  3.699846  3.702923  3.738539  \n",
       "4     2.372660  2.812410  2.606741  2.464537  2.190254  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "3906  2.744390  2.670801  2.791678  2.739287  2.175364  \n",
       "3907  3.415915  3.511111  3.421340  3.148365  3.035161  \n",
       "3908  3.022676  3.148523  3.220136  3.445342  2.865385  \n",
       "3909  3.827273  3.852465  3.807061  3.847542  3.894267  \n",
       "3910  3.070874  3.449126  3.252110  2.981187  3.246317  \n",
       "\n",
       "[3911 rows x 81 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_df[feats] = features\n",
    "oof_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T05:29:28.910783Z",
     "iopub.status.busy": "2022-11-29T05:29:28.910318Z",
     "iopub.status.idle": "2022-11-29T05:29:29.117330Z",
     "shell.execute_reply": "2022-11-29T05:29:29.115788Z",
     "shell.execute_reply.started": "2022-11-29T05:29:28.910746Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "sys.path.append('/kaggle/input/multilabel-stratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "def create_folds(data, num_splits):\n",
    "    data[\"kfold\"] = -1\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=num_splits, shuffle=True, random_state=7)\n",
    "    labels = [\"cohesion\", \"syntax\", \"vocabulary\", \"phraseology\", \"grammar\", \"conventions\"]\n",
    "    data_labels = data[labels].values\n",
    "    for f, (t_, v_) in enumerate(mskf.split(data, data_labels)):\n",
    "        data.loc[v_, \"kfold\"] = f\n",
    "\n",
    "    return data\n",
    "\n",
    "data = create_folds(oof_df,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T05:31:49.955220Z",
     "iopub.status.busy": "2022-11-29T05:31:49.954733Z",
     "iopub.status.idle": "2022-11-29T05:31:50.004081Z",
     "shell.execute_reply": "2022-11-29T05:31:50.002652Z",
     "shell.execute_reply.started": "2022-11-29T05:31:49.955184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col0</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>...</th>\n",
       "      <th>col56</th>\n",
       "      <th>col57</th>\n",
       "      <th>col58</th>\n",
       "      <th>col59</th>\n",
       "      <th>col60</th>\n",
       "      <th>col61</th>\n",
       "      <th>col62</th>\n",
       "      <th>col63</th>\n",
       "      <th>col64</th>\n",
       "      <th>col65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.963322</td>\n",
       "      <td>2.851745</td>\n",
       "      <td>3.079232</td>\n",
       "      <td>3.097821</td>\n",
       "      <td>3.035727</td>\n",
       "      <td>2.800188</td>\n",
       "      <td>2.905647</td>\n",
       "      <td>2.712398</td>\n",
       "      <td>3.098406</td>\n",
       "      <td>3.137756</td>\n",
       "      <td>...</td>\n",
       "      <td>3.125459</td>\n",
       "      <td>3.190478</td>\n",
       "      <td>3.196349</td>\n",
       "      <td>2.759905</td>\n",
       "      <td>2.980735</td>\n",
       "      <td>2.835174</td>\n",
       "      <td>3.170818</td>\n",
       "      <td>3.228327</td>\n",
       "      <td>3.237290</td>\n",
       "      <td>2.741138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.843607</td>\n",
       "      <td>2.688936</td>\n",
       "      <td>2.899376</td>\n",
       "      <td>2.858508</td>\n",
       "      <td>2.490706</td>\n",
       "      <td>2.679547</td>\n",
       "      <td>2.845474</td>\n",
       "      <td>2.702387</td>\n",
       "      <td>2.963810</td>\n",
       "      <td>2.712420</td>\n",
       "      <td>...</td>\n",
       "      <td>2.964808</td>\n",
       "      <td>2.631736</td>\n",
       "      <td>2.597791</td>\n",
       "      <td>2.538102</td>\n",
       "      <td>2.617372</td>\n",
       "      <td>2.424425</td>\n",
       "      <td>2.787720</td>\n",
       "      <td>2.749041</td>\n",
       "      <td>2.504684</td>\n",
       "      <td>2.660148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.877301</td>\n",
       "      <td>2.900978</td>\n",
       "      <td>3.044960</td>\n",
       "      <td>2.898928</td>\n",
       "      <td>2.955909</td>\n",
       "      <td>3.149401</td>\n",
       "      <td>2.868120</td>\n",
       "      <td>2.874635</td>\n",
       "      <td>3.114243</td>\n",
       "      <td>2.881338</td>\n",
       "      <td>...</td>\n",
       "      <td>3.102823</td>\n",
       "      <td>2.969282</td>\n",
       "      <td>3.015122</td>\n",
       "      <td>2.955758</td>\n",
       "      <td>2.927259</td>\n",
       "      <td>2.872589</td>\n",
       "      <td>3.009427</td>\n",
       "      <td>2.989432</td>\n",
       "      <td>3.138277</td>\n",
       "      <td>3.040892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.709563</td>\n",
       "      <td>3.703306</td>\n",
       "      <td>3.871459</td>\n",
       "      <td>3.771405</td>\n",
       "      <td>3.729018</td>\n",
       "      <td>3.824048</td>\n",
       "      <td>3.635967</td>\n",
       "      <td>3.620107</td>\n",
       "      <td>3.801861</td>\n",
       "      <td>3.653327</td>\n",
       "      <td>...</td>\n",
       "      <td>4.027184</td>\n",
       "      <td>3.896751</td>\n",
       "      <td>3.941613</td>\n",
       "      <td>3.769177</td>\n",
       "      <td>3.609747</td>\n",
       "      <td>3.580019</td>\n",
       "      <td>3.711982</td>\n",
       "      <td>3.699846</td>\n",
       "      <td>3.702923</td>\n",
       "      <td>3.738539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.401905</td>\n",
       "      <td>2.360212</td>\n",
       "      <td>2.802807</td>\n",
       "      <td>2.705976</td>\n",
       "      <td>2.706934</td>\n",
       "      <td>2.256478</td>\n",
       "      <td>2.427323</td>\n",
       "      <td>2.465084</td>\n",
       "      <td>2.687973</td>\n",
       "      <td>2.440547</td>\n",
       "      <td>...</td>\n",
       "      <td>2.649640</td>\n",
       "      <td>2.740055</td>\n",
       "      <td>2.587462</td>\n",
       "      <td>2.310569</td>\n",
       "      <td>2.433649</td>\n",
       "      <td>2.372660</td>\n",
       "      <td>2.812410</td>\n",
       "      <td>2.606741</td>\n",
       "      <td>2.464537</td>\n",
       "      <td>2.190254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3906</th>\n",
       "      <td>2.528209</td>\n",
       "      <td>2.611595</td>\n",
       "      <td>2.770499</td>\n",
       "      <td>2.813644</td>\n",
       "      <td>2.664971</td>\n",
       "      <td>2.180138</td>\n",
       "      <td>2.594011</td>\n",
       "      <td>2.495946</td>\n",
       "      <td>2.827858</td>\n",
       "      <td>2.846410</td>\n",
       "      <td>...</td>\n",
       "      <td>2.847502</td>\n",
       "      <td>2.849612</td>\n",
       "      <td>2.645768</td>\n",
       "      <td>2.241242</td>\n",
       "      <td>2.676923</td>\n",
       "      <td>2.744390</td>\n",
       "      <td>2.670801</td>\n",
       "      <td>2.791678</td>\n",
       "      <td>2.739287</td>\n",
       "      <td>2.175364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>3.627993</td>\n",
       "      <td>3.334414</td>\n",
       "      <td>3.623081</td>\n",
       "      <td>3.451083</td>\n",
       "      <td>3.133774</td>\n",
       "      <td>3.339598</td>\n",
       "      <td>3.523348</td>\n",
       "      <td>3.240285</td>\n",
       "      <td>3.494922</td>\n",
       "      <td>3.322443</td>\n",
       "      <td>...</td>\n",
       "      <td>3.556110</td>\n",
       "      <td>3.405059</td>\n",
       "      <td>3.109952</td>\n",
       "      <td>3.174611</td>\n",
       "      <td>3.742900</td>\n",
       "      <td>3.415915</td>\n",
       "      <td>3.511111</td>\n",
       "      <td>3.421340</td>\n",
       "      <td>3.148365</td>\n",
       "      <td>3.035161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>3.012970</td>\n",
       "      <td>2.960456</td>\n",
       "      <td>3.121825</td>\n",
       "      <td>3.276449</td>\n",
       "      <td>3.418097</td>\n",
       "      <td>2.793657</td>\n",
       "      <td>2.873064</td>\n",
       "      <td>2.993003</td>\n",
       "      <td>3.303614</td>\n",
       "      <td>3.369499</td>\n",
       "      <td>...</td>\n",
       "      <td>3.295261</td>\n",
       "      <td>3.373523</td>\n",
       "      <td>3.541609</td>\n",
       "      <td>2.943113</td>\n",
       "      <td>3.040246</td>\n",
       "      <td>3.022676</td>\n",
       "      <td>3.148523</td>\n",
       "      <td>3.220136</td>\n",
       "      <td>3.445342</td>\n",
       "      <td>2.865385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>3.921140</td>\n",
       "      <td>3.916481</td>\n",
       "      <td>3.982096</td>\n",
       "      <td>4.007552</td>\n",
       "      <td>4.094439</td>\n",
       "      <td>4.109852</td>\n",
       "      <td>3.812394</td>\n",
       "      <td>3.758009</td>\n",
       "      <td>3.962001</td>\n",
       "      <td>3.932942</td>\n",
       "      <td>...</td>\n",
       "      <td>3.922573</td>\n",
       "      <td>3.876611</td>\n",
       "      <td>3.640419</td>\n",
       "      <td>3.903100</td>\n",
       "      <td>3.753411</td>\n",
       "      <td>3.827273</td>\n",
       "      <td>3.852465</td>\n",
       "      <td>3.807061</td>\n",
       "      <td>3.847542</td>\n",
       "      <td>3.894267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>3.222808</td>\n",
       "      <td>3.112877</td>\n",
       "      <td>3.459251</td>\n",
       "      <td>3.401690</td>\n",
       "      <td>2.992901</td>\n",
       "      <td>3.309845</td>\n",
       "      <td>3.115099</td>\n",
       "      <td>3.071913</td>\n",
       "      <td>3.317086</td>\n",
       "      <td>3.252189</td>\n",
       "      <td>...</td>\n",
       "      <td>3.447617</td>\n",
       "      <td>3.222591</td>\n",
       "      <td>2.972023</td>\n",
       "      <td>3.171258</td>\n",
       "      <td>3.329528</td>\n",
       "      <td>3.070874</td>\n",
       "      <td>3.449126</td>\n",
       "      <td>3.252110</td>\n",
       "      <td>2.981187</td>\n",
       "      <td>3.246317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3911 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          col0      col1      col2      col3      col4      col5      col6  \\\n",
       "0     2.963322  2.851745  3.079232  3.097821  3.035727  2.800188  2.905647   \n",
       "1     2.843607  2.688936  2.899376  2.858508  2.490706  2.679547  2.845474   \n",
       "2     2.877301  2.900978  3.044960  2.898928  2.955909  3.149401  2.868120   \n",
       "3     3.709563  3.703306  3.871459  3.771405  3.729018  3.824048  3.635967   \n",
       "4     2.401905  2.360212  2.802807  2.705976  2.706934  2.256478  2.427323   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3906  2.528209  2.611595  2.770499  2.813644  2.664971  2.180138  2.594011   \n",
       "3907  3.627993  3.334414  3.623081  3.451083  3.133774  3.339598  3.523348   \n",
       "3908  3.012970  2.960456  3.121825  3.276449  3.418097  2.793657  2.873064   \n",
       "3909  3.921140  3.916481  3.982096  4.007552  4.094439  4.109852  3.812394   \n",
       "3910  3.222808  3.112877  3.459251  3.401690  2.992901  3.309845  3.115099   \n",
       "\n",
       "          col7      col8      col9  ...     col56     col57     col58  \\\n",
       "0     2.712398  3.098406  3.137756  ...  3.125459  3.190478  3.196349   \n",
       "1     2.702387  2.963810  2.712420  ...  2.964808  2.631736  2.597791   \n",
       "2     2.874635  3.114243  2.881338  ...  3.102823  2.969282  3.015122   \n",
       "3     3.620107  3.801861  3.653327  ...  4.027184  3.896751  3.941613   \n",
       "4     2.465084  2.687973  2.440547  ...  2.649640  2.740055  2.587462   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3906  2.495946  2.827858  2.846410  ...  2.847502  2.849612  2.645768   \n",
       "3907  3.240285  3.494922  3.322443  ...  3.556110  3.405059  3.109952   \n",
       "3908  2.993003  3.303614  3.369499  ...  3.295261  3.373523  3.541609   \n",
       "3909  3.758009  3.962001  3.932942  ...  3.922573  3.876611  3.640419   \n",
       "3910  3.071913  3.317086  3.252189  ...  3.447617  3.222591  2.972023   \n",
       "\n",
       "         col59     col60     col61     col62     col63     col64     col65  \n",
       "0     2.759905  2.980735  2.835174  3.170818  3.228327  3.237290  2.741138  \n",
       "1     2.538102  2.617372  2.424425  2.787720  2.749041  2.504684  2.660148  \n",
       "2     2.955758  2.927259  2.872589  3.009427  2.989432  3.138277  3.040892  \n",
       "3     3.769177  3.609747  3.580019  3.711982  3.699846  3.702923  3.738539  \n",
       "4     2.310569  2.433649  2.372660  2.812410  2.606741  2.464537  2.190254  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "3906  2.241242  2.676923  2.744390  2.670801  2.791678  2.739287  2.175364  \n",
       "3907  3.174611  3.742900  3.415915  3.511111  3.421340  3.148365  3.035161  \n",
       "3908  2.943113  3.040246  3.022676  3.148523  3.220136  3.445342  2.865385  \n",
       "3909  3.903100  3.753411  3.827273  3.852465  3.807061  3.847542  3.894267  \n",
       "3910  3.171258  3.329528  3.070874  3.449126  3.252110  2.981187  3.246317  \n",
       "\n",
       "[3911 rows x 66 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_score = 0.0\n",
    "repeats = ['text_id','full_text','cohesion','syntax','vocabulary','phraseology','grammar','conventions','fold','kfold'] + [col for col in data.columns if col.startswith(\"p\")]\n",
    "labels = [\"cohesion\", \"syntax\", \"vocabulary\", \"phraseology\", \"grammar\", \"conventions\"]\n",
    "features = [col for col in data.columns if col not in repeats]\n",
    "oof_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T05:31:52.535491Z",
     "iopub.status.busy": "2022-11-29T05:31:52.535036Z",
     "iopub.status.idle": "2022-11-29T05:31:52.544442Z",
     "shell.execute_reply": "2022-11-29T05:31:52.542813Z",
     "shell.execute_reply.started": "2022-11-29T05:31:52.535455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_oofs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T05:31:52.851852Z",
     "iopub.status.busy": "2022-11-29T05:31:52.850986Z",
     "iopub.status.idle": "2022-11-29T05:31:52.900884Z",
     "shell.execute_reply": "2022-11-29T05:31:52.899368Z",
     "shell.execute_reply.started": "2022-11-29T05:31:52.851809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col0</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>...</th>\n",
       "      <th>col56</th>\n",
       "      <th>col57</th>\n",
       "      <th>col58</th>\n",
       "      <th>col59</th>\n",
       "      <th>col60</th>\n",
       "      <th>col61</th>\n",
       "      <th>col62</th>\n",
       "      <th>col63</th>\n",
       "      <th>col64</th>\n",
       "      <th>col65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.963322</td>\n",
       "      <td>2.851745</td>\n",
       "      <td>3.079232</td>\n",
       "      <td>3.097821</td>\n",
       "      <td>3.035727</td>\n",
       "      <td>2.800188</td>\n",
       "      <td>2.905647</td>\n",
       "      <td>2.712398</td>\n",
       "      <td>3.098406</td>\n",
       "      <td>3.137756</td>\n",
       "      <td>...</td>\n",
       "      <td>3.125459</td>\n",
       "      <td>3.190478</td>\n",
       "      <td>3.196349</td>\n",
       "      <td>2.759905</td>\n",
       "      <td>2.980735</td>\n",
       "      <td>2.835174</td>\n",
       "      <td>3.170818</td>\n",
       "      <td>3.228327</td>\n",
       "      <td>3.237290</td>\n",
       "      <td>2.741138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.843607</td>\n",
       "      <td>2.688936</td>\n",
       "      <td>2.899376</td>\n",
       "      <td>2.858508</td>\n",
       "      <td>2.490706</td>\n",
       "      <td>2.679547</td>\n",
       "      <td>2.845474</td>\n",
       "      <td>2.702387</td>\n",
       "      <td>2.963810</td>\n",
       "      <td>2.712420</td>\n",
       "      <td>...</td>\n",
       "      <td>2.964808</td>\n",
       "      <td>2.631736</td>\n",
       "      <td>2.597791</td>\n",
       "      <td>2.538102</td>\n",
       "      <td>2.617372</td>\n",
       "      <td>2.424425</td>\n",
       "      <td>2.787720</td>\n",
       "      <td>2.749041</td>\n",
       "      <td>2.504684</td>\n",
       "      <td>2.660148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.877301</td>\n",
       "      <td>2.900978</td>\n",
       "      <td>3.044960</td>\n",
       "      <td>2.898928</td>\n",
       "      <td>2.955909</td>\n",
       "      <td>3.149401</td>\n",
       "      <td>2.868120</td>\n",
       "      <td>2.874635</td>\n",
       "      <td>3.114243</td>\n",
       "      <td>2.881338</td>\n",
       "      <td>...</td>\n",
       "      <td>3.102823</td>\n",
       "      <td>2.969282</td>\n",
       "      <td>3.015122</td>\n",
       "      <td>2.955758</td>\n",
       "      <td>2.927259</td>\n",
       "      <td>2.872589</td>\n",
       "      <td>3.009427</td>\n",
       "      <td>2.989432</td>\n",
       "      <td>3.138277</td>\n",
       "      <td>3.040892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.709563</td>\n",
       "      <td>3.703306</td>\n",
       "      <td>3.871459</td>\n",
       "      <td>3.771405</td>\n",
       "      <td>3.729018</td>\n",
       "      <td>3.824048</td>\n",
       "      <td>3.635967</td>\n",
       "      <td>3.620107</td>\n",
       "      <td>3.801861</td>\n",
       "      <td>3.653327</td>\n",
       "      <td>...</td>\n",
       "      <td>4.027184</td>\n",
       "      <td>3.896751</td>\n",
       "      <td>3.941613</td>\n",
       "      <td>3.769177</td>\n",
       "      <td>3.609747</td>\n",
       "      <td>3.580019</td>\n",
       "      <td>3.711982</td>\n",
       "      <td>3.699846</td>\n",
       "      <td>3.702923</td>\n",
       "      <td>3.738539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.401905</td>\n",
       "      <td>2.360212</td>\n",
       "      <td>2.802807</td>\n",
       "      <td>2.705976</td>\n",
       "      <td>2.706934</td>\n",
       "      <td>2.256478</td>\n",
       "      <td>2.427323</td>\n",
       "      <td>2.465084</td>\n",
       "      <td>2.687973</td>\n",
       "      <td>2.440547</td>\n",
       "      <td>...</td>\n",
       "      <td>2.649640</td>\n",
       "      <td>2.740055</td>\n",
       "      <td>2.587462</td>\n",
       "      <td>2.310569</td>\n",
       "      <td>2.433649</td>\n",
       "      <td>2.372660</td>\n",
       "      <td>2.812410</td>\n",
       "      <td>2.606741</td>\n",
       "      <td>2.464537</td>\n",
       "      <td>2.190254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3906</th>\n",
       "      <td>2.528209</td>\n",
       "      <td>2.611595</td>\n",
       "      <td>2.770499</td>\n",
       "      <td>2.813644</td>\n",
       "      <td>2.664971</td>\n",
       "      <td>2.180138</td>\n",
       "      <td>2.594011</td>\n",
       "      <td>2.495946</td>\n",
       "      <td>2.827858</td>\n",
       "      <td>2.846410</td>\n",
       "      <td>...</td>\n",
       "      <td>2.847502</td>\n",
       "      <td>2.849612</td>\n",
       "      <td>2.645768</td>\n",
       "      <td>2.241242</td>\n",
       "      <td>2.676923</td>\n",
       "      <td>2.744390</td>\n",
       "      <td>2.670801</td>\n",
       "      <td>2.791678</td>\n",
       "      <td>2.739287</td>\n",
       "      <td>2.175364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>3.627993</td>\n",
       "      <td>3.334414</td>\n",
       "      <td>3.623081</td>\n",
       "      <td>3.451083</td>\n",
       "      <td>3.133774</td>\n",
       "      <td>3.339598</td>\n",
       "      <td>3.523348</td>\n",
       "      <td>3.240285</td>\n",
       "      <td>3.494922</td>\n",
       "      <td>3.322443</td>\n",
       "      <td>...</td>\n",
       "      <td>3.556110</td>\n",
       "      <td>3.405059</td>\n",
       "      <td>3.109952</td>\n",
       "      <td>3.174611</td>\n",
       "      <td>3.742900</td>\n",
       "      <td>3.415915</td>\n",
       "      <td>3.511111</td>\n",
       "      <td>3.421340</td>\n",
       "      <td>3.148365</td>\n",
       "      <td>3.035161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>3.012970</td>\n",
       "      <td>2.960456</td>\n",
       "      <td>3.121825</td>\n",
       "      <td>3.276449</td>\n",
       "      <td>3.418097</td>\n",
       "      <td>2.793657</td>\n",
       "      <td>2.873064</td>\n",
       "      <td>2.993003</td>\n",
       "      <td>3.303614</td>\n",
       "      <td>3.369499</td>\n",
       "      <td>...</td>\n",
       "      <td>3.295261</td>\n",
       "      <td>3.373523</td>\n",
       "      <td>3.541609</td>\n",
       "      <td>2.943113</td>\n",
       "      <td>3.040246</td>\n",
       "      <td>3.022676</td>\n",
       "      <td>3.148523</td>\n",
       "      <td>3.220136</td>\n",
       "      <td>3.445342</td>\n",
       "      <td>2.865385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>3.921140</td>\n",
       "      <td>3.916481</td>\n",
       "      <td>3.982096</td>\n",
       "      <td>4.007552</td>\n",
       "      <td>4.094439</td>\n",
       "      <td>4.109852</td>\n",
       "      <td>3.812394</td>\n",
       "      <td>3.758009</td>\n",
       "      <td>3.962001</td>\n",
       "      <td>3.932942</td>\n",
       "      <td>...</td>\n",
       "      <td>3.922573</td>\n",
       "      <td>3.876611</td>\n",
       "      <td>3.640419</td>\n",
       "      <td>3.903100</td>\n",
       "      <td>3.753411</td>\n",
       "      <td>3.827273</td>\n",
       "      <td>3.852465</td>\n",
       "      <td>3.807061</td>\n",
       "      <td>3.847542</td>\n",
       "      <td>3.894267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>3.222808</td>\n",
       "      <td>3.112877</td>\n",
       "      <td>3.459251</td>\n",
       "      <td>3.401690</td>\n",
       "      <td>2.992901</td>\n",
       "      <td>3.309845</td>\n",
       "      <td>3.115099</td>\n",
       "      <td>3.071913</td>\n",
       "      <td>3.317086</td>\n",
       "      <td>3.252189</td>\n",
       "      <td>...</td>\n",
       "      <td>3.447617</td>\n",
       "      <td>3.222591</td>\n",
       "      <td>2.972023</td>\n",
       "      <td>3.171258</td>\n",
       "      <td>3.329528</td>\n",
       "      <td>3.070874</td>\n",
       "      <td>3.449126</td>\n",
       "      <td>3.252110</td>\n",
       "      <td>2.981187</td>\n",
       "      <td>3.246317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3911 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          col0      col1      col2      col3      col4      col5      col6  \\\n",
       "0     2.963322  2.851745  3.079232  3.097821  3.035727  2.800188  2.905647   \n",
       "1     2.843607  2.688936  2.899376  2.858508  2.490706  2.679547  2.845474   \n",
       "2     2.877301  2.900978  3.044960  2.898928  2.955909  3.149401  2.868120   \n",
       "3     3.709563  3.703306  3.871459  3.771405  3.729018  3.824048  3.635967   \n",
       "4     2.401905  2.360212  2.802807  2.705976  2.706934  2.256478  2.427323   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3906  2.528209  2.611595  2.770499  2.813644  2.664971  2.180138  2.594011   \n",
       "3907  3.627993  3.334414  3.623081  3.451083  3.133774  3.339598  3.523348   \n",
       "3908  3.012970  2.960456  3.121825  3.276449  3.418097  2.793657  2.873064   \n",
       "3909  3.921140  3.916481  3.982096  4.007552  4.094439  4.109852  3.812394   \n",
       "3910  3.222808  3.112877  3.459251  3.401690  2.992901  3.309845  3.115099   \n",
       "\n",
       "          col7      col8      col9  ...     col56     col57     col58  \\\n",
       "0     2.712398  3.098406  3.137756  ...  3.125459  3.190478  3.196349   \n",
       "1     2.702387  2.963810  2.712420  ...  2.964808  2.631736  2.597791   \n",
       "2     2.874635  3.114243  2.881338  ...  3.102823  2.969282  3.015122   \n",
       "3     3.620107  3.801861  3.653327  ...  4.027184  3.896751  3.941613   \n",
       "4     2.465084  2.687973  2.440547  ...  2.649640  2.740055  2.587462   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3906  2.495946  2.827858  2.846410  ...  2.847502  2.849612  2.645768   \n",
       "3907  3.240285  3.494922  3.322443  ...  3.556110  3.405059  3.109952   \n",
       "3908  2.993003  3.303614  3.369499  ...  3.295261  3.373523  3.541609   \n",
       "3909  3.758009  3.962001  3.932942  ...  3.922573  3.876611  3.640419   \n",
       "3910  3.071913  3.317086  3.252189  ...  3.447617  3.222591  2.972023   \n",
       "\n",
       "         col59     col60     col61     col62     col63     col64     col65  \n",
       "0     2.759905  2.980735  2.835174  3.170818  3.228327  3.237290  2.741138  \n",
       "1     2.538102  2.617372  2.424425  2.787720  2.749041  2.504684  2.660148  \n",
       "2     2.955758  2.927259  2.872589  3.009427  2.989432  3.138277  3.040892  \n",
       "3     3.769177  3.609747  3.580019  3.711982  3.699846  3.702923  3.738539  \n",
       "4     2.310569  2.433649  2.372660  2.812410  2.606741  2.464537  2.190254  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "3906  2.241242  2.676923  2.744390  2.670801  2.791678  2.739287  2.175364  \n",
       "3907  3.174611  3.742900  3.415915  3.511111  3.421340  3.148365  3.035161  \n",
       "3908  2.943113  3.040246  3.022676  3.148523  3.220136  3.445342  2.865385  \n",
       "3909  3.903100  3.753411  3.827273  3.852465  3.807061  3.847542  3.894267  \n",
       "3910  3.171258  3.329528  3.070874  3.449126  3.252110  2.981187  3.246317  \n",
       "\n",
       "[3911 rows x 66 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T05:32:00.814468Z",
     "iopub.status.busy": "2022-11-29T05:32:00.813818Z",
     "iopub.status.idle": "2022-11-29T05:32:01.112683Z",
     "shell.execute_reply": "2022-11-29T05:32:01.111171Z",
     "shell.execute_reply.started": "2022-11-29T05:32:00.814416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0 ====  Train Score: (0.44108933047298976, [0.471853719006943, 0.4353774506681814, 0.39950799741801063, 0.4442589937992913, 0.46064413930874565, 0.434893682636767])\n",
      "Fold: 0 ====  Valid Score: (0.4458452912195179, [0.46611777331592047, 0.44164689252119893, 0.42730461276817877, 0.4441585092596175, 0.4576129136457933, 0.43823104580639843])\n",
      "Fold: 1 ====  Train Score: (0.4386519954710159, [0.46580855073284655, 0.43583772922830855, 0.4008231689293841, 0.43874632890575427, 0.45580855202239834, 0.4348876430074036])\n",
      "Fold: 1 ====  Valid Score: (0.4545741201654851, [0.489406156230043, 0.43800823053151106, 0.4207828601418334, 0.4643178928542624, 0.4768438199450416, 0.438085761290219])\n",
      "Fold: 2 ====  Train Score: (0.4393389163449302, [0.465822335682409, 0.4330931393706596, 0.4061281176566383, 0.44019156494411826, 0.4573467351807594, 0.433451605234997])\n",
      "Fold: 2 ====  Valid Score: (0.4517206257988255, [0.48994487519813323, 0.44974400889095134, 0.3991201749361936, 0.458082451222782, 0.46979737851025555, 0.44363486603463714])\n",
      "Fold: 3 ====  Train Score: (0.4427274827697378, [0.47175729544996403, 0.4344642875343379, 0.40635909849575635, 0.4466681138910403, 0.4613060613196972, 0.43581003992763095])\n",
      "Fold: 3 ====  Valid Score: (0.43814065977338673, [0.4659229010262779, 0.44388740872459775, 0.3992660463122151, 0.43242155469796184, 0.4543140929858049, 0.4330319548934628])\n",
      "Fold: 4 ====  Train Score: (0.439701572178454, [0.4705428192892251, 0.4344469722583297, 0.40452208271884266, 0.4426987760386935, 0.4566978427531265, 0.4293009400125065])\n",
      "Fold: 4 ====  Valid Score: (0.4504538875457114, [0.4709928111701795, 0.44278726641060817, 0.4061936561518094, 0.4503806800753689, 0.473023032011303, 0.45934587945499983])\n",
      "OOF Score: 0.44814691690058533\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  feats = data[data['kfold'] != i][features].reset_index(drop=True).values\n",
    "  val = data[data['kfold'] == i][features].reset_index(drop=True).values\n",
    "  yt =  data[data['kfold'] != i][labels].reset_index(drop=True)\n",
    "  yv = data[data['kfold'] == i][labels].reset_index(drop=True)\n",
    "  stacker = Ridge()\n",
    "  stacker.fit(feats,yt)\n",
    "  train_preds = stacker.predict(feats)\n",
    "  train_score = get_score(yt.values,train_preds)\n",
    "  print(f\"Fold: {i} ====  Train Score: {train_score}\")\n",
    "  val_preds = stacker.predict(val)\n",
    "  val_score = get_score(yv.values,val_preds)\n",
    "  print(f\"Fold: {i} ====  Valid Score: {val_score}\")\n",
    "  pickle.dump(stacker, open(f\"ridge{i}.pkl\", \"wb\" ) )\n",
    "  oof_score += val_score[0]/5\n",
    "print(f\"OOF Score: {oof_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T05:32:22.437097Z",
     "iopub.status.busy": "2022-11-29T05:32:22.436520Z",
     "iopub.status.idle": "2022-11-29T05:32:22.448018Z",
     "shell.execute_reply": "2022-11-29T05:32:22.445974Z",
     "shell.execute_reply.started": "2022-11-29T05:32:22.437047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3129, 66)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T00:53:13.995969Z",
     "iopub.status.busy": "2022-11-29T00:53:13.992502Z",
     "iopub.status.idle": "2022-11-29T00:53:14.017662Z",
     "shell.execute_reply": "2022-11-29T00:53:14.016065Z",
     "shell.execute_reply.started": "2022-11-29T00:53:13.995913Z"
    },
    "papermill": {
     "duration": 0.014446,
     "end_time": "2022-09-08T02:59:41.909458",
     "exception": false,
     "start_time": "2022-09-08T02:59:41.895012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "def prepare_input(cfg, text):\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text, \n",
    "        return_tensors=None, \n",
    "        add_special_tokens=True, \n",
    "        #max_length=CFG.max_len,\n",
    "        #pad_to_max_length=True,\n",
    "        #truncation=True\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['full_text'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, self.texts[item])\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T00:53:14.029488Z",
     "iopub.status.busy": "2022-11-29T00:53:14.025951Z",
     "iopub.status.idle": "2022-11-29T00:53:14.089075Z",
     "shell.execute_reply": "2022-11-29T00:53:14.087659Z",
     "shell.execute_reply.started": "2022-11-29T00:53:14.029427Z"
    },
    "papermill": {
     "duration": 0.024494,
     "end_time": "2022-09-08T02:59:41.945014",
     "exception": false,
     "start_time": "2022-09-08T02:59:41.92052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "class MaxPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaxPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        embeddings = last_hidden_state.clone()\n",
    "        embeddings[input_mask_expanded == 0] = -1e4\n",
    "        max_embeddings, _ = torch.max(embeddings, dim = 1)\n",
    "        return max_embeddings\n",
    "    \n",
    "class MinPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MinPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        embeddings = last_hidden_state.clone()\n",
    "        embeddings[input_mask_expanded == 0] = 1e-4\n",
    "        min_embeddings, _ = torch.min(embeddings, dim = 1)\n",
    "        return min_embeddings\n",
    "        \n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "            self.config.hidden_dropout = 0.\n",
    "            self.config.hidden_dropout_prob = 0.\n",
    "            self.config.attention_dropout = 0.\n",
    "            self.config.attention_probs_dropout_prob = 0.\n",
    "            LOGGER.info(self.config)\n",
    "        else:\n",
    "            self.config = AutoConfig.from_pretrained(config_path, output_hidden_states=True)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        if self.cfg.gradient_checkpointing:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "        self.pool = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 6)\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(feature)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T00:53:14.099231Z",
     "iopub.status.busy": "2022-11-29T00:53:14.098532Z",
     "iopub.status.idle": "2022-11-29T00:53:14.124760Z",
     "shell.execute_reply": "2022-11-29T00:53:14.123149Z",
     "shell.execute_reply.started": "2022-11-29T00:53:14.099178Z"
    }
   },
   "outputs": [],
   "source": [
    "class FB3Model(nn.Module):\n",
    "    def __init__(self, CFG, config_path = None, pretrained = False):\n",
    "        super().__init__()\n",
    "        self.CFG = CFG\n",
    "        self.CFG.init_weight = \"normal\"\n",
    "\n",
    "        self.config = AutoConfig.from_pretrained(config_path, output_hidden_states=True)\n",
    "        self.model = AutoModel.from_config(self.config)\n",
    "        \n",
    "        self.pool = MeanPooling()      \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.dropout4 = nn.Dropout(0.4)\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.output = nn.Linear(self.config.hidden_size, 6)\n",
    "        self._init_weights(self.output)\n",
    "\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if CFG.init_weight == 'normal':\n",
    "                module.weight.data.normal_(mean = 0.0, std = self.config.initializer_range)\n",
    "            elif CFG.init_weight == 'xavier_uniform':\n",
    "                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'xavier_normal':\n",
    "                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_uniform':\n",
    "                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_normal':\n",
    "                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'orthogonal':\n",
    "                module.weight.data = nn.init.orthogonal_(module.weight.data)\n",
    "                \n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            if CFG.init_weight == 'normal':\n",
    "                module.weight.data.normal_(mean = 0.0, std = self.config.initializer_range)\n",
    "            elif CFG.init_weight == 'xavier_uniform':\n",
    "                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'xavier_normal':\n",
    "                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_uniform':\n",
    "                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n",
    "            elif CFG.init_weight == 'kaiming_normal':\n",
    "                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n",
    "            elif CFG.init_weight == 'orthogonal':\n",
    "                module.weight.data = nn.init.orthogonal_(module.weight.data)\n",
    "                \n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n",
    "    \n",
    "            \n",
    "        return feature\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.feature(inputs)\n",
    "        logits1 = self.output(self.dropout1(embeds))\n",
    "        logits2 = self.output(self.dropout2(embeds))\n",
    "        logits3 = self.output(self.dropout3(embeds))\n",
    "        logits4 = self.output(self.dropout4(embeds))\n",
    "        logits5 = self.output(self.dropout5(embeds))\n",
    "        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# inference\n",
    "# ====================================================\n",
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions\n",
    "for _idx, CFG in enumerate(CFG_list):\n",
    "    test = pd.read_csv('../input/feedback-prize-english-language-learning/test.csv')\n",
    "    submission = pd.read_csv('../input/feedback-prize-english-language-learning/sample_submission.csv')\n",
    "    # sort by length to speed up inference\n",
    "    test['tokenize_length'] = [len(CFG.tokenizer(text)['input_ids']) for text in test['full_text'].values]\n",
    "    test = test.sort_values('tokenize_length', ascending=True).reset_index(drop=True)\n",
    "\n",
    "    test_dataset = TestDataset(CFG, test)\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                             batch_size=CFG.batch_size,\n",
    "                             shuffle=False,\n",
    "                             collate_fn=DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding='longest'),\n",
    "                             num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    predictions = []\n",
    "    for fold in CFG.trn_fold:\n",
    "        if _idx == 0:\n",
    "            model = FB3Model(CFG,config_path=CFG.config_path,pretrained = False)\n",
    "        else:\n",
    "            model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n",
    "        state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "                           map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(state['model'])\n",
    "        prediction = inference_fn(test_loader, model, device)\n",
    "        predictions.append(prediction)\n",
    "        del model, state, prediction; gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    predictions = np.mean(predictions, axis=0)\n",
    "    test[CFG.target_cols] = predictions\n",
    "    submission = submission.drop(columns=CFG.target_cols).merge(test[['text_id'] + CFG.target_cols], on='text_id', how='left')\n",
    "    #display(submission.head())\n",
    "    submission[['text_id'] + CFG.target_cols].to_csv(f'submission_{_idx}.csv', index=False)\n",
    "    del test, submission, predictions, test_dataset, test_loader; gc.collect()\n",
    "    torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.041042,
     "end_time": "2022-09-08T03:07:32.078302",
     "exception": false,
     "start_time": "2022-09-08T03:07:32.03726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/feedback-prize-english-language-learning/test.csv')\n",
    "submission = pd.read_csv('../input/feedback-prize-english-language-learning/sample_submission.csv')\n",
    "sub0 = pd.read_csv(\"submission_0.csv\").drop(columns=\"text_id\")\n",
    "sub1 = pd.read_csv(\"submission_1.csv\").drop(columns=\"text_id\")\n",
    "sub2 = pd.read_csv(f'submission_2.csv').drop(columns=\"text_id\")\n",
    "sub3 = pd.read_csv(\"submission_3.csv\").drop(columns=\"text_id\")\n",
    "sub4 = pd.read_csv(f'submission_4.csv').drop(columns=\"text_id\")\n",
    "sub5 = pd.read_csv(f'submission_5.csv').drop(columns=\"text_id\")\n",
    "sub6 = pd.read_csv(f'submission_6.csv').drop(columns=\"text_id\")\n",
    "sub7 = pd.read_csv(f'submission_7.csv').drop(columns=\"text_id\")\n",
    "sub8 = pd.read_csv(f'submission_8.csv').drop(columns=\"text_id\")\n",
    "sub9 = pd.read_csv(f'submission_9.csv').drop(columns=\"text_id\")\n",
    "sub10 = pd.read_csv(\"submission_10.csv\").drop(columns=\"text_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subs = []\n",
    "all_subs.append(sub0)\n",
    "all_subs.append(sub1)\n",
    "all_subs.append(sub2)\n",
    "all_subs.append(sub3)\n",
    "all_subs.append(sub4)\n",
    "all_subs.append(sub5)\n",
    "all_subs.append(sub6)\n",
    "all_subs.append(sub7)\n",
    "all_subs.append(sub8)\n",
    "all_subs.append(sub9)\n",
    "all_subs.append(sub10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = pd.concat(all_subs,axis=1)\n",
    "total_predictions = pd.concat(all_subs,axis=1)\n",
    "final_preds = []\n",
    "for i in range(5):\n",
    "    ridge = pickle.load(open(f'ridge{i}.pkl','rb'))\n",
    "    predictions = ridge.predict(total_predictions)\n",
    "    final_preds.append(predictions)\n",
    "ens = np.mean(final_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[CFG1.target_cols] = ens\n",
    "display(submission.head())\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
